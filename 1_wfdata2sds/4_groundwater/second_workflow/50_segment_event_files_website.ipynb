{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1375df-472a-4d38-ad81-e98287c6d681",
   "metadata": {},
   "source": [
    "# Segment SDS Archive based on launch event times and generate event web browser\n",
    "Launch times come from 'PilotStudy_KSC_Rocket_Launches.xlsx'\n",
    "SDS archives are at SDS_TOP and contain data from seismo-acoustic stations\n",
    "Well data come only from pickle files now, and those are in local time with sensor data converted to PSI\n",
    "Segmented event waveform files are saved as MiniSEED to EVENT_WAVEFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b69344-1775-461c-bf51-a450c082023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import header\n",
    "paths = header.setup_environment()\n",
    "paths['SDS_TOP'] = os.path.join(paths['outdir'], 'SDS')\n",
    "HTML_DIR = '/var/www/html/thompsong/KSC_EROSION/EVENTS'\n",
    "PNG_DIR = os.path.join(HTML_DIR, 'images')\n",
    "EVENT_WAVEFORMS = os.path.join(paths['outdir'], 'EVENTS') # must exist, and Excel file must be here\n",
    "csv_launches = os.path.join(paths['outdir'], 'PilotStudy_KSC_Rocket_Launches.csv')\n",
    "csv_launches_detected = os.path.join(paths['outdir'], 'PilotStudy_KSC_Rocket_Launches_detected.csv')\n",
    "#import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import obspy\n",
    "#import FDSNtools\n",
    "#import wrappers\n",
    "import SDS\n",
    "import libWellData as LLE\n",
    "\n",
    "#import libDatascopeGT\n",
    "from obspy.clients.filesystem.sds import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce87ff8-66a6-48fa-b887-6eeede0f6905",
   "metadata": {},
   "source": [
    "# Setup dataframe to iterate over launches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4510b4-973c-47e2-9897-8b5629a53f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure directories exist\n",
    "for thisdir in [EVENT_WAVEFORMS, HTML_DIR, PNG_DIR]:\n",
    "    if not os.path.isdir(thisdir):\n",
    "        os.makedirs(thisdir)\n",
    "\n",
    "# Read launch data into a DataFrame and generate a list of launch times in Python datetime.datetime format\n",
    "startover = True # starts with original CSV file again\n",
    "if os.path.isfile(csv_launches_detected) and startover==False:\n",
    "    launchesDF = LLE.removed_unnamed_columns(pd.read_csv(csv_launches_detected, index_col=None))\n",
    "else:\n",
    "    launchesDF = LLE.removed_unnamed_columns(pd.read_csv(csv_launches, index_col=None))\n",
    "    dt_tmp = pd.to_datetime(launchesDF['Date'] + ' ' +  launchesDF['Time'])\n",
    "    launchesDF['Date'] = [pdt.to_pydatetime() for pdt in dt_tmp]\n",
    "    launchesDF.drop(labels='Time', axis=1, inplace=True)\n",
    "    del dt_tmp\n",
    "\n",
    "# make sure dataframe has columns to track processing done\n",
    "if not 'rawfile' in launchesDF.columns:\n",
    "    launchesDF['rawfile'] = ''\n",
    "if not 'corrected_file' in launchesDF.columns: \n",
    "    launchesDF['corrected_file'] = ''\n",
    "if not 'detection_time' in launchesDF.columns:\n",
    "    launchesDF['detection_time'] = '' \n",
    "if not 'short_file' in launchesDF.columns:\n",
    "    launchesDF['short_file'] = ''\n",
    "if not 'plotted' in launchesDF.columns:\n",
    "    launchesDF['plotted'] = False     \n",
    "\n",
    "# output new dataframe\n",
    "launchesDF.to_csv(csv_launches_detected) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e51c0-737f-4a55-bfae-dbfc843d079e",
   "metadata": {},
   "source": [
    "# Read 2 hours of raw seismo-acoustic data for each event from SDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963d9b3-3b05-4bd3-8828-06044ecdc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_sds2rawfile_and_plot(launchtime, thisSDSobj, EVENT_WAVEFORMS, pretrig=3600, posttrig=3600, overwrite=False):    \n",
    "    rawfile = os.path.join(EVENT_WAVEFORMS, '%s_raw.pkl' % launchtime.strftime('%Y%m%dT%H%M%S'))\n",
    "    if os.path.exists(rawfile) and not overwrite:\n",
    "        print('%s already exists' % rawfile)\n",
    "    else:\n",
    "        print('segmenting %s from SDS' % rawfile) \n",
    "        startt = launchtime - pretrig\n",
    "        endt = launchtime + posttrig\n",
    "        thisSDSobj.read(startt, endt, speed=1)\n",
    "        st4 = thisSDSobj.stream\n",
    "\n",
    "        if len(st)>0:\n",
    "            try:\n",
    "                st.write(rawfile, format='pickle')\n",
    "            except:\n",
    "                st2 = Stream()\n",
    "                for tr in st:\n",
    "                    try:\n",
    "                        tr.write('tmp.pkl', 'pickle')\n",
    "                        st2.append(tr)\n",
    "                    except:\n",
    "                        print('Failed:\\n',tr)\n",
    "                st=st2\n",
    "                if len(st)>0:\n",
    "                    st.write(rawfile, format='pickle')\n",
    "                else:\n",
    "                    rawfile=None\n",
    "        else:\n",
    "            print('Got no data')\n",
    "            rawfile = None\n",
    "    if rawfile:\n",
    "        rawpng = os.path.join(PNG_DIR, os.path.basename(rawfile.replace('.pkl','.png')))\n",
    "        if not os.path.exists(rawpng):\n",
    "            print('creating raw file plot ',rawpng)\n",
    "            st.plot(equal_scale=False, outfile=rawpng)\n",
    "    return rawfile\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351e05d-e0b0-418f-91ba-e54aa2ceea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each launch, segment raw SDS data to multi-trace MiniSEED file in EVENT_WAVEFORMS directory\n",
    "thisSDSobj = SDS.SDSobj(paths['SDS_TOP'])\n",
    "print(launchesDF)\n",
    "for i, row in launchesDF.iterrows():\n",
    "    launchTime = obspy.UTCDateTime(row['Date'])\n",
    "    if not row['corrected_file']:\n",
    "        print('Processing launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S')) \n",
    "        print(row)\n",
    "\n",
    "        # RAW DATA, FILE AND PLOT\n",
    "        if row['rawfile']:\n",
    "            rawfile = os.path.join(EVENT_WAVEFORMS, row['rawfile'])\n",
    "        else:\n",
    "            rawfile = event_sds2rawfile_and_plot(launchTime, thisSDSobj, EVENT_WAVEFORMS, overwrite=False, pretrig=3600, posttrig=3600)\n",
    "            if rawfile:\n",
    "                launchesDF.at[i, 'rawfile'] = os.path.basename(rawfile)\n",
    "            else:\n",
    "                raise Exception('failed to create %s' % rawfile)\n",
    "del thisSDSobj\n",
    "launchesDF.to_csv(csv_launches_detected) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4627c-d7be-40f5-b56c-80a1a09d7fe5",
   "metadata": {},
   "source": [
    "# Correct seismo-acoustic data, saving 2-hour waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70f856-eb07-4537-964b-605c1f0ee461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(st):\n",
    "    for tr in st:\n",
    "        if tr.stats.network != 'FL':\n",
    "            continue\n",
    "        tr.detrend('linear')\n",
    "        tr.filter('highpass', freq=0.2, corners=2) \n",
    "        \n",
    "def apply_calibration_correction(st):\n",
    "    # calibration correction\n",
    "\n",
    "    for tr in st:\n",
    "        if 'countsPerUnit' in tr.stats:\n",
    "            continue\n",
    "        else:\n",
    "            tr.stats['countsPerUnit'] = 1\n",
    "            if not 'units' in tr.stats:\n",
    "                tr.stats['units'] = 'Counts'\n",
    "            if tr.stats.station[0].isnumeric(): # well data\n",
    "                if len(tr.stats.network)==0:\n",
    "                    tr.stats.network = '6'\n",
    "                if tr.stats.channel[2] == 'D':\n",
    "                    tr.stats.countsPerUnit = 1/LLE.psi2inches(1) # counts (psi) per inch\n",
    "                    tr.stats.units = 'inches'\n",
    "                elif tr.stats.channel[2] == 'H':\n",
    "                    tr.stats.countsPerUnit = 1/6894.76 # counts (psi) per Pa\n",
    "                    tr.stats.units = 'Pa'\n",
    "            elif tr.stats.channel[1]=='D':\n",
    "                tr.stats.countsPerUnit = 720 # counts/Pa on 1 V FS setting\n",
    "                if tr.id[:-1] == 'FL.BCHH3.10.HD':\n",
    "                    if tr.stats.starttime < obspy.UTCDateTime(2022,5,26): # Chaparral M25. I had it set to 1 V FS. Should have used 40 V FS. \n",
    "                        if tr.id == 'FL.BCHH3.10.HDF':\n",
    "                            tr.stats.countsPerUnit = 8e5 # counts/Pa\n",
    "                        else:\n",
    "                            tr.stats.countsPerUnit = 720 # counts/Pa \n",
    "                    else: # Chaparral switched to 40 V FS\n",
    "                        if tr.id == 'FL.BCHH3.10.HDF':\n",
    "                            tr.stats.countsPerUnit = 2e4 # counts/Pa\n",
    "                        else:\n",
    "                            tr.stats.countsPerUnit = 18 # counts/Pa \n",
    "                tr.stats.units = 'Pa'\n",
    "\n",
    "            elif tr.stats.channel[1]=='H':\n",
    "                tr.stats.countsPerUnit = 3e2 # counts/(um/s)\n",
    "                tr.stats.units = 'um/s'\n",
    "            tr.data = tr.data/tr.stats.countsPerUnit\n",
    "    \n",
    "def maxamp(tr):\n",
    "    return np.max(np.abs(tr.data))\n",
    "\n",
    "def remove_spikes(st):\n",
    "    SEISMIC_MAX = 0.1 # m/s\n",
    "    INFRASOUND_MAX = 3000 # Pa\n",
    "    FEET_MAX = 21 # feet\n",
    "    #SEISMIC_MIN = 1e-9\n",
    "    #INFRASOUND_MIN = 0.01\n",
    "    \n",
    "    for tr in st:\n",
    "        ma = maxamp(tr)\n",
    "        if tr.stats.units == 'm/s':\n",
    "            tr.data[tr.data > SEISMIC_MAX] = np.nan\n",
    "            tr.data[tr.data < -1 * SEISMIC_MAX] = np.nan             \n",
    "        elif tr.stats.units == 'Pa':\n",
    "            tr.data[tr.data > INFRASOUND_MAX] = np.nan\n",
    "            tr.data[tr.data < -1 * INFRASOUND_MAX] = np.nan   \n",
    "        elif tr.stats.units == 'feet':\n",
    "            tr.data[tr.data > FEET_MAX] = np.nan\n",
    "            tr.data[tr.data < -1 * FEET_MAX] = np.nan    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4698486-173e-4b90-9083-b91535a07c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in launchesDF.iterrows():\n",
    "    launchTime = obspy.UTCDateTime(row['Date'])\n",
    "    if not row['corrected_file']:\n",
    "        print('Processing launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S')) \n",
    "        print(row)\n",
    "        if row['rawfile']:\n",
    "            rawfile = os.path.join(EVENT_WAVEFORMS, row['rawfile'])\n",
    "        \n",
    "            try:\n",
    "                st = obspy.read(rawfile)    \n",
    "                #st.merge(method=0, fill_value=0)\n",
    "            except:\n",
    "                st = obspy.Stream()\n",
    "            print('%s: %d channels' % (rawfile,len(st)))\n",
    "\n",
    "            if len(st)>0:\n",
    "    \n",
    "                # CORRECT DATA, and WRITE\n",
    "                clean(st) \n",
    "                apply_calibration_correction(st)\n",
    "                remove_spikes(st)\n",
    "                correctedfile =  os.path.join(EVENT_WAVEFORMS, '%s_long.pkl' % launchTime.strftime('%Y%m%dT%H%M%S'))\n",
    "                print('Writing %s' % correctedfile)\n",
    "                try:\n",
    "                    st.write(correctedfile, format='PICKLE') # save 2-hour event waveforms\n",
    "                    launchesDF.at[i, 'corrected_file'] = os.path.basename(correctedfile)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "launchesDF.to_csv(csv_launches_detected) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75100937-fd8c-4f21-872f-2904f7ce39a4",
   "metadata": {},
   "source": [
    "# Detect seismo-acoustic event(s) within 2-hour waveform window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b9089-5d92-463d-baed-047aad7fbe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.signal.trigger import coincidence_trigger\n",
    "from pprint import pprint\n",
    "import matplotlib.dates as dates\n",
    "def detectEvent(st, launchtime):\n",
    "    trig = coincidence_trigger(\"recstalta\", 3.5, 1, st, 3, sta=2, lta=40)\n",
    "    best_trig = {}\n",
    "    best_product = 0\n",
    "    for this_trig in trig:\n",
    "        thistime = dates.date2num(this_trig['time'])\n",
    "        this_product = this_trig['coincidence_sum']*this_trig['duration']\n",
    "        if this_product > best_product:\n",
    "            best_trig = this_trig\n",
    "            best_product = this_product\n",
    "    pprint(best_trig)\n",
    "    return best_trig['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a323867-9ffb-4d57-afeb-9060c6c9e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "startover = True\n",
    "for i, row in launchesDF.iterrows():\n",
    "    if row['detection_time'] and startover==False:\n",
    "        continue\n",
    "    launchTime = obspy.UTCDateTime(row['Date'])\n",
    "    if row['corrected_file']:\n",
    "        correctedfile =  os.path.join(EVENT_WAVEFORMS, row['corrected_file'])\n",
    "    else:\n",
    "        continue\n",
    "    print('Detecting launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S'))                        \n",
    "\n",
    "    # subset out the seismo-acoustic traces for detection purposes\n",
    "    if not os.path.isfile(correctedfile):\n",
    "        print('File not found: ',correctedfile)\n",
    "        continue\n",
    "    st = obspy.read(correctedfile)\n",
    "    '''\n",
    "    SA = st.copy().select(network='FL').trim(starttime=launchTime-100, endtime=launchTime+200)\n",
    "    MTEGL = st.copy().select(network='XA').trim(starttime=launchTime-100, endtime=launchTime+200)\n",
    "    if len(MTEGL)>0:\n",
    "        for tr in MTEGL:\n",
    "            SA.append(tr)\n",
    "    '''\n",
    "    SA = st.copy().select(channel='?[NHD]?').trim(starttime=launchTime-100, endtime=launchTime+200)\n",
    "    if len(SA)==0:\n",
    "        continue\n",
    "        \n",
    "\n",
    "    assocTime = detectEvent(SA, launchTime)\n",
    "            \n",
    "    if abs(assocTime-launchTime)>100:\n",
    "        assocTime=launchTime\n",
    "    launchesDF.at[i, 'detection_time'] = assocTime\n",
    "launchesDF.to_csv(csv_launches_detected) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a63fe-0285-4d94-9a3c-16b8b4b9396b",
   "metadata": {},
   "source": [
    "# Write short seismo-acoustic files (3 minutes long only) based on network detection time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46282e5c-129e-40d6-9e9b-6df3355501f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrig = 30\n",
    "posttrig = 150\n",
    "overwrite = True\n",
    "for i, row in launchesDF.iterrows():                       \n",
    "    if not row['short_file'] or overwrite:\n",
    "        launchTime = obspy.UTCDateTime(row['Date']) \n",
    "        print('- Creating short file for launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S')) \n",
    "        if row['corrected_file']:\n",
    "            correctedfile =  os.path.join(EVENT_WAVEFORMS, row['corrected_file'])\n",
    "        else:\n",
    "            continue   \n",
    "        if not os.path.isfile(correctedfile):\n",
    "            print('File not found: ',correctedfile)\n",
    "            continue\n",
    "        # save 3-minute event waveforms\n",
    "        st = obspy.read(correctedfile)\n",
    "        if len(st)==0:\n",
    "            continue\n",
    "\n",
    "        assocTime = row['detection_time']\n",
    "        if not assocTime:\n",
    "            continue\n",
    "        st_short = st.copy()\n",
    "        #st_short.filter('highpass', freq=0.1, corners=2)\n",
    "        st_short.trim(starttime=assocTime-pretrig, endtime=assocTime+posttrig)\n",
    "        print(st_short)\n",
    "        if len(st_short)>0:\n",
    "            # write shorter corrected event out\n",
    "            shortfile =  os.path.join(EVENT_WAVEFORMS, '%s_short.pkl' % launchTime.strftime('%Y%m%dT%H%M%S'))\n",
    "            print('Writing %s' % shortfile)\n",
    "            try:\n",
    "                st_short.write(shortfile, format='PICKLE') # save 2-hour event waveforms\n",
    "            except:\n",
    "                pass\n",
    "            launchesDF.at[i, 'short_file'] = os.path.basename(shortfile)\n",
    "launchesDF.to_csv(csv_launches_detected)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b33b8-785c-46be-8dbb-3df5671e2734",
   "metadata": {},
   "source": [
    "# Make plots of long (2-hour corrected seismo-acoustic) data and short (3-minute corrected seismo-acoustic) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00948d5-d33c-4af3-b709-71779fc7f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def group_streams_for_plotting(st):\n",
    "def group_streams_for_plotting(streamSA):\n",
    "    groups = {}\n",
    "    #streamSA = st.select(network='FL')\n",
    "    stationsSA = list(set([tr.stats.station for tr in streamSA]))\n",
    "    for station in stationsSA:\n",
    "        stationStream = streamSA.select(station=station)\n",
    "        #stationIDS = list(set([tr.id for tr in stationStream]))\n",
    "        groups[station] = stationStream\n",
    "    #print(groups)\n",
    "    return groups  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef241ad5-21ad-41b4-9496-7851e803b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "launchesDF['plotted']=None\n",
    "for i, row in launchesDF.iterrows():\n",
    "    if row['plotted']:\n",
    "        continue\n",
    "    launchTime = obspy.UTCDateTime(row['Date'])\n",
    "    #assocTime = row['detection_time']\n",
    "    print('- Plotting launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S')) \n",
    "    for ext in ['long', 'short']:\n",
    "        if ext=='short':\n",
    "            pklfile = row['short_file']\n",
    "        else:    \n",
    "            pklfile = row['corrected_file']\n",
    "        if not pklfile:\n",
    "            continue\n",
    "        pklfile = os.path.join(EVENT_WAVEFORMS, pklfile)\n",
    "        if not os.path.isfile(pklfile):\n",
    "            print('File not found: ',pklfile)\n",
    "            continue\n",
    "        st = obspy.read(pklfile)\n",
    "        if len(st)==0:\n",
    "            continue        \n",
    "        groups = group_streams_for_plotting(st)\n",
    "        for station, stream_group in groups.items():\n",
    "            if len(stream_group)>0:\n",
    "                pngfile = os.path.join(PNG_DIR, '%s_%s_%s.png' % (launchTime.strftime('%Y%m%dT%H%M%S'), station, ext))\n",
    "                stream_group.plot(equal_scale=False, outfile=pngfile)\n",
    "    launchesDF.at[i, 'plotted'] = True\n",
    "launchesDF.to_csv(csv_launches_detected) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9c66c-a439-4a07-8a6c-250cab2a25dc",
   "metadata": {},
   "source": [
    "# Make plots of long (2-hour well) data and short (3-minute well) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c90f9-9f5b-4131-865a-1392b73f4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in launchesDF.iterrows():\n",
    "    launchTime = obspy.UTCDateTime(row['Date'])\n",
    "    print(launchTime)\n",
    "    #if launchTime < obspy.UTCDateTime(2022,11,16) or launchTime > obspy.UTCDateTime(2022,11,17):\n",
    "    #    continue\n",
    "    assocTime = row['detection_time']\n",
    "    print('- Plotting launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S')) \n",
    "    for ext in ['long', 'short']:\n",
    "        #pngfile = os.path.join(PNG_DIR, '%s_%s_%s.png' % (launchTime.strftime('%Y%m%dT%H%M%S'), station, ext))\n",
    "        LLE.plot_high_resolution_well_data(launchTime, assocTime, duration=0, pretrig=pretrig, posttrig=posttrig)\n",
    "        # pngfile = f\"{start_dt.strftime('%Y%m%d_%H%M')}_{instruments}_{fs}Hz.png\"\n",
    "        # pngpath = os.path.join(EVENT_WAVEFORMS, pngfile)    \n",
    "        \n",
    "        #LLE.plot_low_resolution_well_data(launchTime, duration=0, pretrig=3600, posttrig=3600)\n",
    "        try:\n",
    "            #LLE.plot_60s_well_data(launchTime, assocTime, duration=0, pretrig=3600, posttrig=3600)\n",
    "            #LLE.plot_low_resolution_well_data(launchTime, assocTime, duration=0, pretrig=3600, posttrig=3600, new_interval=1)\n",
    "            LLE.plot_high_resolution_well_data(launchTime, assocTime, duration=0, pretrig=3600, posttrig=3600, ext='long', print_dataframe=True)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd3014-4f24-4024-8939-5c95c514c79c",
   "metadata": {},
   "source": [
    "# Make website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935506a8-7ba0-4e2d-88a8-6146973aadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_DIR = '/var/www/html/thompsong/KSC_EROSION/EVENTS'\n",
    "#PNG_DIR = os.path.join(HTML_DIR, 'images')\n",
    "#EVENT_WAVEFORMS = os.path.join(paths['outdir'], 'EVENTS') # must exist, and Excel file must be here\n",
    "#csv_launches_detected = os.path.join(paths['outdir'], 'PilotStudy_KSC_Rocket_Launches_detected.csv')\n",
    "\n",
    "#launchesDF = LLE.removed_unnamed_columns(pd.read_csv(csv_launches_detected, index_col=None))\n",
    "\n",
    "for thisdir in [HTML_DIR, PNG_DIR]:\n",
    "    if not os.path.isdir(thisdir):\n",
    "        os.makedirs(thisdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9abaf9-39a7-4574-8210-52eb620f4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_event_html(i, row, groups, ext='short',peakmeas=None,units=None):\n",
    "    stations = groups.keys()\n",
    "    launchTime = obspy.UTCDateTime(row['Date'])    \n",
    "    lts = launchTime.strftime('%Y%m%dT%H%M%S')\n",
    "    lts_human = launchTime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    htmlfile = os.path.join(HTML_DIR, 'launch_%s_%s.html' % (lts, ext))\n",
    "    nl = '\\n'\n",
    "    print(f\"Writing {htmlfile}\")\n",
    "    contents = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>\"\"\"\n",
    "    contents = f\"Event {lts_human}</title>\\n</head>\\n\\n<body>{nl}\"\n",
    "\n",
    "    # EVENT INFO\n",
    "    contents += \"<table border=1>\\n\"\n",
    "    contents += f\"<tr> <th>Event Number:</th> <td>{i}</td> </tr>\\n\"\n",
    "    contents += f\"<tr> <th>Date/Time:</th> <td>{lts_human} {launchTime.timestamp,} ({launchTime.strftime('%j')}) </td> </tr>{nl}\"\n",
    "    contents += f\"<tr> <th>Detection time:</th> <td>{row['detection_time']}</td> </tr>{nl}\"\n",
    "    contents += f\"<tr> <th>Rocket/Payload:</th> <td>{row['Rocket_Payload']}</td> </tr>{nl}\"\n",
    "    contents += f\"<tr> <th>Launchpad:</th> <td>{row['SLC']}</td> </tr>{nl}\"\n",
    "    contents += f\"<tr> <th>Notes:</th> <td>{row['Notes']}</td> </tr>{nl}\"\n",
    "    contents += \"</table>\\n\"\n",
    "    \n",
    "    # PLOTS\n",
    "    contents += \"<table border=1>\\n\"\n",
    "\n",
    "    # well instrument groups\n",
    "    instrumentsList = ['Baro', 'Sensors', 'Sensors', 'Sensors']\n",
    "    fsList = [100, 1, 20, 100]\n",
    "    for instrumentIndex, instruments in enumerate(instrumentsList):\n",
    "        fs = fsList[instrumentIndex]    \n",
    "        stationname = f'{instruments} {fs}Hz'\n",
    "        pngpath = os.path.join(os.path.basename(PNG_DIR), f\"{lts}_{instruments}_{fs}Hz_{ext}.png\") \n",
    "        contents += f\"<tr> <td><h1>{stationname}</h1></td> <td><a href='{pngpath}'><img src='{pngpath}'></a><td/> {nl}\"\n",
    "        contents += \"</tr> \\n\"\n",
    "            \n",
    "    # seismo-acoustic stations\n",
    "    for stationname in groups.keys():\n",
    "        ids = [tr.id for tr in groups[stationname]] \n",
    "        pngfile = os.path.join(os.path.basename(PNG_DIR), '%s_%s_%s.png' % (lts, stationname, ext))\n",
    "        contents += f\"<tr> <td><h1>{stationname}</h1></td> <td><a href='{pngfile}'><img src='{pngfile}'></a><td/> {nl}\"\n",
    "        if peakmeas:\n",
    "            contents += \"<td>\"\n",
    "            for id in ids:\n",
    "                try:\n",
    "                    thispeakstr = '%.2e' % peakmeas[id]\n",
    "                    contents += f\"{id}: {thispeakstr} {units[id]} <br/>{nl}\"    \n",
    "                except:\n",
    "                    pass  \n",
    "            contents += \"</td>\"\n",
    "        contents += \"</tr> \\n\"\n",
    "\n",
    "    contents += \"</table>\\n\"\n",
    "    \n",
    "    contents += \"</body>\\n</html>\"\n",
    "    fptr = open(htmlfile, \"w\")\n",
    "    fptr.write(contents)\n",
    "    fptr.close()\n",
    "    #print(contents)\n",
    "    return os.path.basename(htmlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97890761-13e9-4e9f-a2fb-c5a20e56523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_index_html(launchesDF):\n",
    "    contents0 = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>Events</title>\n",
    "</head>\n",
    "<body>\n",
    "<table border=1>\n",
    "<tr><th>Date</th><th>Rocket/Payload</th><th>Launchpad</th><th>Raw</th><th>Short</th><th>Long</th><th>Strength (um/s)</th></tr>\n",
    "    \"\"\"    \n",
    "    for i, row in launchesDF.iterrows():\n",
    "\n",
    "        print(i, 'of ', len(launchesDF) )\n",
    "\n",
    "        launchTime = obspy.UTCDateTime(row['Date'])    \n",
    "        lts = launchTime.strftime('%Y%m%dT%H%M%S')\n",
    "        lts_human = launchTime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        contents0 += f\"<tr> <td>{lts_human} ({launchTime.timestamp,} {launchTime.strftime('%j')}) </td> \"\n",
    "        contents0 += f\"<td>{row['Rocket_Payload']}</td> <td>{row['SLC']}</td> \"\n",
    "        rawpng = os.path.join(EVENT_WAVEFORMS, row['rawfile'].replace('.pkl','.png'))\n",
    "        if os.path.isfile(rawpng):\n",
    "            contents0 += f\"<td><a href={rawpng}>raw</a></td> \"\n",
    "        else:\n",
    "            contents0 += \"<td>None</td> \"\n",
    "\n",
    "        Zpeak = 0 \n",
    "        for ext in ['short', 'long']:\n",
    "            if ext=='short':\n",
    "                pklfile = row['short_file']\n",
    "            else:    \n",
    "                pklfile = row['corrected_file']\n",
    "            if not pklfile:\n",
    "                continue\n",
    "            pklfile =  os.path.join(EVENT_WAVEFORMS, pklfile)\n",
    "            print('pklfile=',pklfile) \n",
    "            if os.path.isfile(pklfile):\n",
    "                st = obspy.read(pklfile, 'PICKLE')\n",
    "                groups = group_streams_for_plotting(st)\n",
    "                peakmeas = dict()\n",
    "                units = dict()\n",
    "                if ext=='short':\n",
    "                    for tr in st:\n",
    "                        peakmeas[tr.id] = max(abs(tr.data)) \n",
    "                        units[tr.id] = tr.stats.units\n",
    "                        if tr.stats.channel[1] == 'Z':\n",
    "                            if peakmeas[tr.id] > Zpeak:\n",
    "                                Zpeak = peakmeas[tr.id]\n",
    "\n",
    "                htmlfile = make_event_html(i, row, groups, ext, peakmeas, units)\n",
    "                contents0 += f\"<td><a href={htmlfile}>{ext}</a></td> \"\n",
    "            else:\n",
    "                contents0 += f\"<td>None</td> \"\n",
    "        Zpeakstr = '%.2e' % Zpeak\n",
    "        contents0 += f\"<td>{Zpeakstr}</td> </tr>\"\n",
    "        contents0 += '\\n'\n",
    "    contents0 += \"\\n</table>\\n</body>\\n</html>\"\n",
    "    indexfile = os.path.join(HTML_DIR, 'index.html')\n",
    "    fptr0 = open(indexfile, \"w\")\n",
    "    fptr0.write(contents0)\n",
    "    fptr0.close()    \n",
    "\n",
    "\n",
    "#make_html(UTCDateTime('2022-11-03 05:22:00'), ['S39A1', 'BCHH2'])\n",
    "#print(launchesDF)\n",
    "make_index_html(launchesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98f03f-f17d-44a9-9cd6-3a920a351cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "st = obspy.read('/home/thompsong/work/PROJECTS/KSC_EROSION/EVENTS/20221116T064744_short.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cec8ad-981c-4ae1-88f4-8e92fc75bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafae51-fb70-4a86-90c0-58aa5001612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.select(channel='?[NHD]?').plot(equal_scale=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
