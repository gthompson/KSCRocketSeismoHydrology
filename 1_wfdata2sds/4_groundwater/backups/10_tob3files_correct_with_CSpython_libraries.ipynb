{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04137867",
   "metadata": {},
   "source": [
    "# Convert Phase 2 well data\n",
    "Locher Environmental recorded data from multiple transducers in two adjacent wells near SLC 39A at Kennedy Space Center (KSC), between March and November, 2022. This was part of a seismo-acoustic erosion pilot experiment. During phase 2 of the experiment, which began on July 21st, 2022, vibrating wire sensors were used and found to give more accurate water levels. These data were captured on Campbell Scientific dataloggers and recorded in TOB3 binary file format. The purpose of this notebook is to:\n",
    "- read these files\n",
    "- apply calibration equations\n",
    "- write to pickle files (Python binary files that serialize the data variables)\n",
    "Calibration constants are defined in the transducers dataframe (section 2). These are copied from the file \"A Pz Linear Gage Calc_NASA Sensors.xls\". Other metadata included in this dataframe come from sections 6 and 7 in the file \"2022-12-03_ Field Sheet for Deployment of Groundwater Equipment at NASA_Part_II.pdf\".\n",
    "\n",
    "Note on *TIME ZONES*: \n",
    "- Local time is used in Campbell Scientific binary files, and files converted to Pickle.\n",
    "- UTC is used in MiniSEED files, to match seismo-acoustic data.\n",
    "\n",
    "Note on *UNITS*:\n",
    "- Pi\n",
    "\n",
    "To do:\n",
    "- create a lookup table, matching file name, start time, end time, and SEED trace-ID.\n",
    "\n",
    "\n",
    "# 1. Imports, path variables, and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ccbf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data on April 1, 2022 from 16:10 to 16:40 UTC. Launch from SLC40 at 16:24 UTC, watched from Titusville\n",
    "%run header.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e79699",
   "metadata": {},
   "source": [
    "# 2. Read raw data files, convert to CSV files using CS Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84cfc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read Campbell Scientific TOB3 file\n",
    "write_csv = False\n",
    "write_raw = False\n",
    "keep_existing = False\n",
    "allcolumns = []\n",
    "lod = []\n",
    "\n",
    "# Generate complete list of TOB3 files (raw TOB3 files from CS dataloggers)\n",
    "tob3files = LLE.list_loggernet_tob3files(paths['TOB3_DIR'])\n",
    "\n",
    "for filenum, tob3file in enumerate(tob3files):\n",
    "    tob3base = os.path.basename(tob3file)\n",
    "    print('File %d of %d: %s' % ((filenum+1), len(tob3files), tob3file))\n",
    "    dirname = os.path.basename(os.path.dirname(tob3file))\n",
    "    csvfile = tob3file.replace('.dat','.py_csv')\n",
    "    if os.path.isfile(csvfile) & keep_existing:\n",
    "        print('- Already DONE')\n",
    "    else:\n",
    "        print('- Reading')\n",
    "        data, meta = campbell.read_cs_files(tob3file, forcedatetime=False,\n",
    "                      bycol=True, quiet=True, metaonly=False)\n",
    "        print('- converting to dataframe')\n",
    "        try: # adding because one time meta was just a bool and not subscriptable\n",
    "            df = pd.DataFrame(columns=meta[2]) \n",
    "        except:\n",
    "            continue\n",
    "        for c in range(len(meta[2])):\n",
    "            df[meta[2][c]] = data[c]\n",
    "            if not meta[2][c] in allcolumns:\n",
    "                allcolumns.append(meta[2][c])       \n",
    "        print('- writing raw data to %s' % csvfile)\n",
    "        df.to_csv(csvfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2690cc19",
   "metadata": {},
   "source": [
    "# 3. Read raw CSV files, apply calibration equations, write out to corrected CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complete list of .raw_csv files (raw TOB3 files from CS dataloggers converted by Python library above)\n",
    "pycsvfiles = LLE.list_loggernet_csvfiles(paths['TOB3_DIR'], ext='.py_csv')\n",
    "        \n",
    "LLE.correct_csvfiles(pycsvfiles, paths, converted_by_LoggerNet=False, MAXFILES=None, keep_existing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
