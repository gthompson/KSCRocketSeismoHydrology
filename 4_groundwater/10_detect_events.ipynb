{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import header\n",
    "paths = header.setup_environment()\n",
    "import platform\n",
    "if platform.system()=='Darwin':\n",
    "    INPUTDIR = '/Users/thompsong/Dropbox/PROFESSIONAL/RESEARCH/3_Project_Documents/NASAprojects/201602_Rocket_Seismology/DATA/2022_DATA/WellData/MERGED'\n",
    "else:\n",
    "    INPUTDIR = os.path.join(paths['new_data'], '03_merge_inventories')\n",
    "import libWellData as LLE\n",
    "transducersDF = LLE.get_transducers_dataframe(paths)\n",
    "display(transducersDF)\n",
    "\n",
    "# Load in the summary of all files - raw 4 hourly data \n",
    "dfall2 = pd.read_csv(os.path.join(INPUTDIR, 'all2.csv'))\n",
    "#display(dfall2['subdir'])\n",
    "\n",
    "LLE.qc_dataframe(dfall2)\n",
    "\n",
    "# Split in baro, 20Hz, 100Hz\n",
    "all_dataframes = LLE.split_by_subdir(dfall2, verbose=True)\n",
    "#print(all_dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(dfdata)\n",
    "for k in dfdata.keys():\n",
    "    print(k)\n",
    "    display(dfdata[k])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 10.2: Correct analog and digital air column transducers for calibration, elevation above water, and apply DC shift (no temperature correction)\n",
    "dcshifts2 = {'AirPressureShallow':0.0, 'AirPressureDeep':-0.003058, '1226420':-14.423795, '1226429':-14.556290}\n",
    "aircolumns = ['AirPressureShallow', 'AirPressureDeep', '1226420', '1226429']\n",
    "dfbaro_dcshifted = LLE.correctBarometricData(dfdata['baro'], aircolumns[:2], transducersDF, temperatureCorrect=False, heightCorrect=True, dcshifts=dcshifts2)\n",
    "df100hz_dcshifted = LLE.correctBarometricData(dfdata['100hz'], aircolumns[2:], transducersDF, temperatureCorrect=False, heightCorrect=True, dcshifts=dcshifts2)\n",
    "\n",
    "# 10.4: Correct digital water column transducers for calibration and barometric pressure\n",
    "correctedAllSensorsPSI = LLE.rawdf2psidf(df100hz_dcshifted, transducersDF, temperatureCorrect=False, airpressureCorrect=True, depthCorrect=False)\n",
    "watercolumns = ['1226419', '1226421', '2151691', '2149882']\n",
    "display(correctedAllSensorsPSI[watercolumns])\n",
    "\n",
    "# 10.5: plot PSI\n",
    "correctedAllSensorsPSI.plot(x='datetime', y=aircolumns[2:]+watercolumns, style='-', ylabel='PSI')\n",
    "\n",
    "# 10.6: convert to water levels in meters\n",
    "correctedAllSensorsMeters = LLE.psi2meters(correctedAllSensorsPSI, watercolumns)\n",
    "correctedAllSensorsMeters.plot(x='datetime', y=watercolumns, style='-', ylabel='Meters')\n",
    "\n",
    "# 10.7: convert to water levels in meters relative to the set depth measured by Steve Krupa\n",
    "relativeAllSensorsMeters = LLE.relative_to_set_depth(correctedAllSensorsMeters, transducersDF, watercolumns)\n",
    "relativeAllSensorsMeters.plot(x='datetime', y=watercolumns, style='-', ylabel='Meters')\n",
    "\n",
    "# 10.8: estimate correct set depths from median of each, and shift by this amount\n",
    "estimatedAllSensorsMeters = LLE.estimate_sensor_depths(correctedAllSensorsMeters, watercolumns)\n",
    "estimatedAllSensorsMeters.plot(x='datetime', y=watercolumns, style='-', ylabel='Meters')   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RSAM simulation\n",
    "import obspy\n",
    "\n",
    "# Create an ObsPy Trace from the DataFrame (we assume 'amplitude' is the seismic data)\n",
    "trace = Trace()\n",
    "trace.data = df['amplitude'].values  # Assign the amplitude as the seismic data\n",
    "trace.stats.station = \"S01\"\n",
    "trace.stats.network = \"NET\"\n",
    "trace.stats.sampling_rate = sampling_rate\n",
    "trace.stats.starttime = obspy.UTCDateTime(df['time'].iloc[0])\n",
    "\n",
    "# Step 2: Create a Stream object containing the Trace\n",
    "stream = Stream(traces=[trace])\n",
    "\n",
    "# Step 3: Display some information\n",
    "print(stream)\n",
    "print(\"Trace Data:\", stream[0].data[:10])  # Print the first 10 samples of the trace data\n",
    "print(\"Trace Stats:\", stream[0].stats)\n",
    "\n",
    "# Plot the Stream data\n",
    "stream.plot()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def simulate_rsam(thisdf, watercolumns, sample_interval_seconds=1):\n",
    "# Step 1: Handle NaN values\n",
    "# We can forward fill the NaN values\n",
    "tr.data = np.nan_to_num(tr.data, nan=np.nanmean(tr.data))  # Replace NaNs with the mean value of the trace\n",
    "\n",
    "# Alternatively, you could use interpolation:\n",
    "# tr.interpolate()  # Uncomment to use linear interpolation\n",
    "\n",
    "# Step 2: Downsample (Resample the Trace)\n",
    "# Let's downsample to 10 Hz\n",
    "new_sampling_rate = 10\n",
    "tr_resampled = tr.resample(sampling_rate=new_sampling_rate)\n",
    "    for col in thisdf.columns:\n",
    "        if col in watercolumns:\n",
    "            print(col)\n",
    "            # Here we replace NaN with 0, perform a linear detrend, apply a 20-s highpass filter, and then compute the absolute value, and put it back into the dataframe\n",
    "            tr = obspy.Trace(data=thisdf[col].to_numpy()) # or use .values instead of to_numpy()\n",
    "            tr.id = f'{col[0:2]}.{col[2:7]}.{col[7:9]}.{col[9:]}\n",
    "            #nan_positions = np.where(np.isnan(tr.data))\n",
    "            tr.data = np.nan_to_num(tr.data, nan=0.0)\n",
    "            tr.detrend('linear')\n",
    "            tr.filter('highpass', freq=0.05)\n",
    "            #tr.data[nan_positions] = np.nan # put the NaNs back?\n",
    "            thisdf[col] = abs(tr.data)\n",
    "    #print(thisdf.columns)\n",
    "    #thisdf.reset_index(inplace=True)\n",
    "    display(thisdf)\n",
    "    # Here we resample the data\n",
    "    resampleddf = thisdf.resample(f'{sample_interval}s', on='datetime').median()\n",
    "    print(resampleddf)\n",
    "    #for col in resampleddf.columns:\n",
    "    #    resampleddf[col] = resampleddf[col]-resampleddf[col][0]\n",
    "    resampleddf.plot(kind='line')\n",
    "    plt.show()\n",
    "\n",
    "    st = obspy.Stream()\n",
    "    for col in resampleddf:\n",
    "        tr2 = obspy.Trace(data=resampleddf[col].to_numpy())\n",
    "        tr2.data = np.nan_to_num(tr2.data, nan=0.0)\n",
    "        tr2.id = f'{col[0:2]}.{col[2:7]}.{col[7:9]}.{col[9:]}' # create SEED ID\n",
    "        tr2.stats.delta = float(sample_interval)\n",
    "        tr2.stats.starttime=obspy.UTCDateTime(resampleddf.index[0])\n",
    "        st.append(tr2)\n",
    "    st.plot(equal_scale=False);\n",
    "    print(st)\n",
    "    return st\n",
    "rsamst = simulate_rsam(estimatedAllSensorsMeters, watercolumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def detrend_dataframe(dforiginal, valuecolumns=[]):\n",
    "    if len(valuecolumns)>0:\n",
    "        df = dforiginal.copy()\n",
    "        for col in valuecolumns:\n",
    "            if col in df.columns:\n",
    "\n",
    "                # Step 1: Handle missing values (e.g., forward-fill)\n",
    "                df[col] = df[col].fillna(method='ffill')  # Forward fill\n",
    "\n",
    "                # Step 2: Detrend the time series using linear regression\n",
    "\n",
    "                # Create an array of time (numerical index)\n",
    "                time = np.arange(len(df)).reshape(-1, 1)\n",
    "\n",
    "                # Fit a linear regression model to the data\n",
    "                model = LinearRegression()\n",
    "                model.fit(time, df['value'])\n",
    "\n",
    "                # Predict the trend\n",
    "                trend = model.predict(time)\n",
    "\n",
    "                # Detrended data: original data - predicted trend\n",
    "                df[col] = df[col] - trend\n",
    "        return df\n",
    "    else:\n",
    "        raise IOError('No columns given')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def high_pass_dataframe(dforiginal, valuecolumns, freqmin=0.2, sampling_rate=100):\n",
    "    if len(valuecolumns)>0:\n",
    "        df = dforiginal.copy()\n",
    "        for col in valuecolumns:\n",
    "            if col in df.columns:\n",
    "\n",
    "                # Step 1: Handle missing values (e.g., forward-fill)\n",
    "                df[col] = df[col].fillna(method='ffill')  # Forward fill\n",
    "\n",
    "                # Step 2: Filter\n",
    "                df[col] = high_pass_filter(df[col], freqmin=freqmin, sampling_rate=sampling_rate)\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        raise IOError('No columns given')\n",
    "\n",
    "\n",
    "\n",
    "# Define the high-pass filter\n",
    "def high_pass_filter(data, cutoff_freq, sampling_rate, order=4):\n",
    "    # Normalize the cutoff frequency\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    \n",
    "    # Design a Butterworth high-pass filter\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    \n",
    "    # Apply the filter using filtfilt (zero-phase filtering)\n",
    "    filtered_data = signal.filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#st.filter('bandpass', freqmin=10, freqmax=20)  # optional prefiltering\n",
    "print(st)\n",
    "from obspy.signal.trigger import coincidence_trigger\n",
    "\n",
    "st2 = st.copy()\n",
    "\n",
    "trigs = coincidence_trigger(\"recstalta\", 2, 1, st2, int(len(st2)/2), sta=sample_interval*5, lta=sample_interval*100)\n",
    "for thistrig in trigs:\n",
    "    display(thistrig)\n",
    "    noisewindow = st2.copy().trim(starttime=thistrig['time']-60, endtime=thistrig['time']-10)\n",
    "    for tr in noisewindow:\n",
    "        if not np.all(tr.data):\n",
    "            thistrig['trace_ids'].remove(tr.id)\n",
    "    if len(thistrig['trace_ids'])>len(st2)/2:\n",
    "        st3 = st2.copy().trim(starttime=thistrig['time']-60, endtime=thistrig['time']+60+thistrig['duration'])\n",
    "        st3.plot(equal_scale=False);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "passoft3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
