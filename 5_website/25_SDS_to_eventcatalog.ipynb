{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDS to website\n",
    "Purpose: By processing a list of events from an Excel spreadsheet, look for existing seismic & infrasound data in an SDS archive, instrument correct those data, and make a webpage for each event \n",
    "\n",
    "Steps:\n",
    "1. Create an event catalog with instrument-corrected data\n",
    "\n",
    "TO DO: \n",
    "* add support for AM network, and any data from networks run by other operators and available on IRIS\n",
    "* add well data from YYYYMMDD_final.pkl files\n",
    "\n",
    "Do we want to turn pkl files into SDS?\n",
    "\n",
    "SCAFFOLD:\n",
    "* add a detector for sonic booms after rocket launch for landers\n",
    "* add any nearby IRIS seismic and infrasound data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Do full workflow for all events\n",
    "* Load and correct seismic and infrasound data from FL network and XA and whatever the network was for PASSCAL equipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n",
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import header\n",
    "paths = header.setup_environment()\n",
    "paths['SDS_TOP'] = '/data/SDS'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import obspy\n",
    "sys.path.append(os.path.join(paths['Developer'], 'SoufriereHillsVolcano', 'lib'))\n",
    "import SDS\n",
    "#import Spectrograms\n",
    "import USF_instrument_responses\n",
    "from obspy.clients.filesystem.sds import Client\n",
    "#f#rom obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "#from obspy.signal.trigger import \n",
    "from pprint import pprint\n",
    "import matplotlib.dates as dates\n",
    "import libseisGT\n",
    "import libWellData as LLE\n",
    "import librockets as LR\n",
    "\n",
    "sdsclient = Client(paths['SDS_TOP'])\n",
    "thisSDSobj = SDS.SDSobj(paths['SDS_TOP'])\n",
    "\n",
    "paths['EVENTS'] = os.path.join(paths['DROPBOX_DATA_TOP'], 'EVENTS')\n",
    "\n",
    "paths['WWW_TOP'] = '/var/www/html/usfseismiclab.org/html/rocketcat'\n",
    "paths['WWW_EVENTS']=os.path.join(paths['WWW_TOP'], 'EVENTS')\n",
    "#paths['WWW_CONTINUOUS'] = os.path.join(paths['WWW_TOP'], 'CONTINUOUS')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for 2022 EROSION PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    paths['csv_launches'] = os.path.join(paths['WWW_TOP'], 'launches.csv')\n",
    "\n",
    "    launchesDF = LLE.removed_unnamed_columns(pd.read_csv(paths['csv_launches'], index_col=None, parse_dates=['datetime']))\n",
    "    #launchesDF['datetime']= pd.to_datetime(launchesDF['Date'] + ' ' +  launchesDF['Time'])\n",
    "    preseconds=120\n",
    "    eventseconds=120\n",
    "    postseconds=120\n",
    "    taperseconds=600\n",
    "\n",
    "    # need to add a detector for sonic booms too!\n",
    "    # 2022 responses\n",
    "    ondate = obspy.UTCDateTime(2022,3,17)\n",
    "    offdate = obspy.UTCDateTime(2022,12,5)\n",
    "\n",
    "    # seismic channels\n",
    "    invs1 = USF_instrument_responses.NRL2inventory('FL', 'S39A1', '00', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invs2 = USF_instrument_responses.NRL2inventory('FL', 'S39A2', '00', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invs3 = USF_instrument_responses.NRL2inventory('FL', 'S39A3', '00', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invs4 = USF_instrument_responses.NRL2inventory('FL', 'BCHH3', '00', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invs5 = USF_instrument_responses.NRL2inventory('FL', 'BCHH4', '10', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    seismicinv = invs1 + invs2 + invs3 + invs4 + invs5\n",
    "\n",
    "    # infrasound\n",
    "    date_BCHH3_change = obspy.UTCDateTime(2022,5,26) # looking at files, it seems we actually have no data for BCHH3 after this - we just called it BCHH4\n",
    "    invi1 = USF_instrument_responses.NRL2inventory('FL', 'S39A1', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi2 = USF_instrument_responses.NRL2inventory('FL', 'S39A2', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi3 = USF_instrument_responses.NRL2inventory('FL', 'S39A3', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi4 = USF_instrument_responses.NRL2inventory('FL', 'BCHH2', '10', ['HD4'], datalogger='Centaur', sensor='Chap', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi5 = USF_instrument_responses.NRL2inventory('FL', 'BCHH2', '10', ['HD5', 'HD6'], datalogger='Centaur', sensor='infraBSU', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi6 = USF_instrument_responses.NRL2inventory('FL', 'BCHH2', '10', ['HD7', 'HD8', 'HD9'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi7 = USF_instrument_responses.NRL2inventory('FL', 'BCHH3', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=date_BCHH3_change)\n",
    "    invi8 = USF_instrument_responses.NRL2inventory('FL', 'BCHH3', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=40, fsamp=100.0, ondate=date_BCHH3_change, offdate=offdate)\n",
    "    invi9 = USF_instrument_responses.NRL2inventory('FL', 'BCHH4', '00', ['HDF', 'HD2', 'HD3'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "\n",
    "    infrainv = invi1 + invi2 + invi3 + invi4 + invi5 + invi6 + invi7 + invi8 + invi9\n",
    "\n",
    "    inv = seismicinv + infrainv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for whole SDS archive of rocket launches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date      Time  SLC                    Rocket_Payload Event type  \\\n",
      "0   2016-02-05  13:38:00   41       Atlas V 401|AV057 GPS 2F-12     launch   \n",
      "1   2016-03-04  23:35:00   40          Falcon 9 1.2|F9-22 SES-9     launch   \n",
      "2   2016-03-23  03:05:52   41     Atlas V 401|AV064 Cygnus OA-6     launch   \n",
      "3   2016-04-08  20:43:31   40  Falcon 9 1.2|F9-023 Dragon/CRS 8     launch   \n",
      "4   2016-05-06  05:21:00   40       Falcon 9 1.2|F9-24 JCSAT 14     launch   \n",
      "..         ...       ...  ...                               ...        ...   \n",
      "180 2022-11-03  05:22:00   40         Falcon 9 Block 5 | F9-184        NaN   \n",
      "181 2022-11-12  16:06:00   40         Falcon 9 Block 5 | F9-185        NaN   \n",
      "182 2022-11-16  06:47:44  39B          SLS Block 1 | Artemis 1         NaN   \n",
      "183 2022-11-23  02:57:00   40         Falcon 9 Block 5 | F9-186        NaN   \n",
      "184 2022-11-26  19:20:43  39A         Falcon 9 Block 5 | F9-187        NaN   \n",
      "\n",
      "    Returned to KSC                     datetime  \n",
      "0               NaN  2016-02-05T13:38:00.000000Z  \n",
      "1               NaN  2016-03-04T23:35:00.000000Z  \n",
      "2               NaN  2016-03-23T03:05:52.000000Z  \n",
      "3               NaN  2016-04-08T20:43:31.000000Z  \n",
      "4               NaN  2016-05-06T05:21:00.000000Z  \n",
      "..              ...                          ...  \n",
      "180             NaN  2022-11-03T05:22:00.000000Z  \n",
      "181             NaN  2022-11-12T16:06:00.000000Z  \n",
      "182             NaN  2022-11-16T06:47:44.000000Z  \n",
      "183             NaN  2022-11-23T02:57:00.000000Z  \n",
      "184             NaN  2022-11-26T19:20:43.000000Z  \n",
      "\n",
      "[185 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# 1. Load and modify the all launches Excel file\n",
    "paths['xls_launches'] = os.path.join('/data', 'KSC','All_KSC_Rocket_Launches.xlsx')\n",
    "\n",
    "launchesDF = LLE.removed_unnamed_columns(pd.read_excel(paths['xls_launches'], index_col=None, parse_dates=['Date']))\n",
    "launchesDF = launchesDF[['Date', 'Time', 'SLC', 'Rocket_Payload', 'Event type', 'Returned to KSC']]\n",
    "#launchesDF['datetime']= pd.to_datetime(launchesDF['Date'] + ' ' +  launchesDF['Time'])\n",
    "\n",
    "try:\n",
    "    time_as_timedelta = pd.to_timedelta(launchesDF['Time'])\n",
    "except:\n",
    "    time_series = launchesDF['Time']\n",
    "    time_as_timedelta = pd.to_timedelta([datetime.timedelta(hours=t.hour, minutes=t.minute, seconds=t.second) for t in time_series])\n",
    "\n",
    "\n",
    "# Combine the date and time series into a single datetime column\n",
    "datetime_series = launchesDF['Date'] + time_as_timedelta\n",
    "\n",
    "# Convert to obspy UTCDateTime format\n",
    "launchesDF['datetime'] = datetime_series.apply(lambda x: obspy.UTCDateTime(x))\n",
    "del datetime_series\n",
    "\n",
    "print(launchesDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preseconds=120\n",
    "eventseconds=120\n",
    "postseconds=120\n",
    "taperseconds=600\n",
    "\n",
    "# need to add a detector for sonic booms too!\n",
    "# 2022 responses\n",
    "ondate = obspy.UTCDateTime(2016, 2, 24)\n",
    "offdate = obspy.UTCDateTime(2022,12,5)\n",
    "\n",
    "xmlfile = 'KSC.xml'\n",
    "if os.path.isfile(xmlfile):\n",
    "    inv = obspy.core.inventory.read_inventory(xmlfile)\n",
    "else:\n",
    "\n",
    "    # seismic channels\n",
    "    invs1 = USF_instrument_responses.NRL2inventory('FL', 'S39A1', '00', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invs2 = USF_instrument_responses.NRL2inventory('FL', 'S39A2', '00', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invs3 = USF_instrument_responses.NRL2inventory('FL', 'S39A3', '00', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invs4 = USF_instrument_responses.NRL2inventory('FL', 'BCHH3', '00', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invs5 = USF_instrument_responses.NRL2inventory('FL', 'BCHH4', '10', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    seismicinv = invs1 + invs2 + invs3 + invs4 + invs5\n",
    "\n",
    "    # infrasound\n",
    "    date_BCHH3_change = obspy.UTCDateTime(2022,5,26) # looking at files, it seems we actually have no data for BCHH3 after this - we just called it BCHH4\n",
    "    invi1 = USF_instrument_responses.NRL2inventory('FL', 'S39A1', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi2 = USF_instrument_responses.NRL2inventory('FL', 'S39A2', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi3 = USF_instrument_responses.NRL2inventory('FL', 'S39A3', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi4 = USF_instrument_responses.NRL2inventory('FL', 'BCHH2', '10', ['HD4'], datalogger='Centaur', sensor='Chap', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi5 = USF_instrument_responses.NRL2inventory('FL', 'BCHH2', '10', ['HD5', 'HD6'], datalogger='Centaur', sensor='infraBSU', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi6 = USF_instrument_responses.NRL2inventory('FL', 'BCHH2', '10', ['HD7', 'HD8', 'HD9'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    invi7 = USF_instrument_responses.NRL2inventory('FL', 'BCHH3', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=date_BCHH3_change)\n",
    "    invi8 = USF_instrument_responses.NRL2inventory('FL', 'BCHH3', '10', ['HDF'], datalogger='Centaur', sensor='infraBSU', Vpp=40, fsamp=100.0, ondate=date_BCHH3_change, offdate=offdate)\n",
    "    invi9 = USF_instrument_responses.NRL2inventory('FL', 'BCHH4', '00', ['HDF', 'HD2', 'HD3'], datalogger='Centaur', sensor='infraBSU', Vpp=1, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "\n",
    "    infrainv = invi1 + invi2 + invi3 + invi4 + invi5 + invi6 + invi7 + invi8 + invi9\n",
    "\n",
    "\n",
    "    for station_num in range(1,9,1):\n",
    "        # 2018-2021\n",
    "        station = f'BHP{station_num}'\n",
    "        invpasscal = USF_instrument_responses.NRL2inventory('1R', station, '', ['EH1', 'EH2', 'EHZ'], datalogger='RT130', sensor='L-22', fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "        seismicinv = seismicinv + invpasscal\n",
    "    for station in ['FIREP', 'TANKP']:\n",
    "        invpasscal = USF_instrument_responses.NRL2inventory('1R', station, '', ['EH1', 'EH2', 'EHZ'], datalogger='RT130', sensor='L-22', fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "        seismicinv = seismicinv + invpasscal\n",
    "\n",
    "    inv0 = USF_instrument_responses.NRL2inventory('FL', 'BCHH1', '0', ['HHZ', 'HHN', 'HHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    seismicinv = seismicinv + inv0\n",
    "    inv1 = USF_instrument_responses.NRL2inventory('FL', 'BCHH1', '0', ['HD1', 'HD2', 'HD3'], datalogger='Centaur', sensor='infraBSU', Vpp=40, fsamp=100.0, ondate=ondate, offdate=offdate)\n",
    "    infrainv = infrainv + inv1\n",
    "\n",
    "    inv2 = USF_instrument_responses.NRL2inventory('FL', 'BCHH', '00', ['GHZ', 'GHN', 'GHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=2000.0, ondate=ondate, offdate=offdate)\n",
    "    seismicinv = seismicinv + inv2\n",
    "    inv3 = USF_instrument_responses.NRL2inventory('FL', 'BCHH', '10', ['GD1', 'GD2', 'GD3'], datalogger='Centaur', sensor='infraBSU', Vpp=40, fsamp=2000.0, ondate=ondate, offdate=offdate)\n",
    "    infrainv = infrainv + inv3\n",
    "\n",
    "    for station in ['BCHH', 'FIRE', 'TANK']:\n",
    "        inv4 = USF_instrument_responses.NRL2inventory('FL', station, '00', ['DHZ', 'DHN', 'DHE'], datalogger='Centaur', sensor='TCP', Vpp=40, fsamp=250.0, ondate=ondate, offdate=offdate)\n",
    "        seismicinv = seismicinv + inv4\n",
    "        inv5 = USF_instrument_responses.NRL2inventory('FL', station, '10', ['DD1', 'DD2', 'DD3'], datalogger='Centaur', sensor='infraBSU', Vpp=40, fsamp=250.0, ondate=ondate, offdate=offdate)\n",
    "        infrainv = infrainv + inv5\n",
    "\n",
    "    inv6 = USF_instrument_responses.NRL2inventory('FL', 'BCHH2', '10', ['HD4', 'HD5', 'HD6', 'HD7', 'HD8', 'HD9'], datalogger='Centaur', sensor='infraBSU', Vpp=40, fsamp=250.0, ondate=ondate, offdate=offdate)\n",
    "    infrainv = infrainv + inv6\n",
    "\n",
    "\n",
    "    inv = seismicinv + infrainv\n",
    "\n",
    "    inv.write(xmlfile, format='STATIONXML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing launch at 2016-03-04 23:35:00\n",
      "FL/\n",
      "    BCHH/\n",
      "        00/GHE\n",
      "        00/GHN\n",
      "        00/GHZ\n",
      "        10/GD1\n",
      "        10/GD2\n",
      "        10/GD3\n",
      "    FIRE/\n",
      "        00/DHE\n",
      "        00/DHN\n",
      "        00/DHZ\n",
      "        10/DD1\n",
      "        10/DD2\n",
      "        10/DD3\n",
      "NZ/\n",
      "    WIZ/\n",
      "        10/HHE\n",
      "        10/HHN\n",
      "        10/HHZ\n",
      "        31/HDF\n",
      "        32/HDF\n",
      "    WSRZ/\n",
      "        10/HHE\n",
      "        10/HHN\n",
      "        10/HHZ\n",
      "        31/HDF\n",
      "        32/HDF\n",
      "12 Trace(s) in Stream:\n",
      "FL.BCHH.00.GHE | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.00.GHN | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.00.GHZ | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.10.GD1 | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.10.GD2 | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.10.GD3 | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 2000.0 Hz, 3120001 samples\n",
      "FL.FIRE.00.DHE | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.00.DHN | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.00.DHZ | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD1 | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD2 | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD3 | 2016-03-04T23:23:00.000000Z - 2016-03-04T23:49:00.000000Z | 250.0 Hz, 390001 samples\n",
      "Processing launch at 2016-03-23 03:05:52\n",
      "FL/\n",
      "    BCHH/\n",
      "        00/GHE\n",
      "        00/GHN\n",
      "        00/GHZ\n",
      "        10/GD1\n",
      "        10/GD2\n",
      "        10/GD3\n",
      "    FIRE/\n",
      "        00/DHE\n",
      "        00/DHN\n",
      "        00/DHZ\n",
      "        10/DD1\n",
      "        10/DD2\n",
      "        10/DD3\n",
      "    TANK/\n",
      "        0/DHE\n",
      "        0/DHN\n",
      "        0/DHZ\n",
      "        10/DD1\n",
      "        10/DD2\n",
      "        10/DD3\n",
      "NZ/\n",
      "    WIZ/\n",
      "        10/HHE\n",
      "        10/HHN\n",
      "        10/HHZ\n",
      "        31/HDF\n",
      "        32/HDF\n",
      "    WSRZ/\n",
      "        10/HHE\n",
      "        10/HHN\n",
      "        10/HHZ\n",
      "        31/HDF\n",
      "        32/HDF\n",
      "12 Trace(s) in Stream:\n",
      "FL.BCHH.00.GHE | 2016-03-23T02:53:52.000001Z - 2016-03-23T03:19:52.000001Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.00.GHN | 2016-03-23T02:53:52.000001Z - 2016-03-23T03:19:52.000001Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.00.GHZ | 2016-03-23T02:53:52.000001Z - 2016-03-23T03:19:52.000001Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.10.GD1 | 2016-03-23T02:53:52.000001Z - 2016-03-23T03:19:52.000001Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.10.GD2 | 2016-03-23T02:53:52.000001Z - 2016-03-23T03:19:52.000001Z | 2000.0 Hz, 3120001 samples\n",
      "FL.BCHH.10.GD3 | 2016-03-23T02:53:52.000001Z - 2016-03-23T03:19:52.000001Z | 2000.0 Hz, 3120001 samples\n",
      "FL.FIRE.00.DHE | 2016-03-23T02:53:52.000000Z - 2016-03-23T03:19:52.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.00.DHN | 2016-03-23T02:53:52.000000Z - 2016-03-23T03:19:52.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.00.DHZ | 2016-03-23T02:53:52.000000Z - 2016-03-23T03:19:52.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD1 | 2016-03-23T02:53:52.000000Z - 2016-03-23T03:19:52.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD2 | 2016-03-23T02:53:52.000000Z - 2016-03-23T03:19:52.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD3 | 2016-03-23T02:53:52.000000Z - 2016-03-23T03:19:52.000000Z | 250.0 Hz, 390001 samples\n",
      "Processing launch at 2016-04-08 20:43:31\n",
      "FL/\n",
      "    FIRE/\n",
      "        00/DHE\n",
      "        00/DHN\n",
      "        00/DHZ\n",
      "        10/DD1\n",
      "        10/DD2\n",
      "        10/DD3\n",
      "    TANK/\n",
      "        0/DHE\n",
      "        0/DHN\n",
      "        0/DHZ\n",
      "        10/DD1\n",
      "        10/DD2\n",
      "        10/DD3\n",
      "NZ/\n",
      "    WIZ/\n",
      "        10/HHE\n",
      "        10/HHN\n",
      "        10/HHZ\n",
      "        31/HDF\n",
      "        32/HDF\n",
      "    WSRZ/\n",
      "        10/HHE\n",
      "        10/HHN\n",
      "        10/HHZ\n",
      "        31/HDF\n",
      "        32/HDF\n",
      "12 Trace(s) in Stream:\n",
      "FL.FIRE.00.DHE | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.00.DHN | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.00.DHZ | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD1 | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD2 | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.FIRE.10.DD3 | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.TANK.0.DHE  | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.TANK.0.DHN  | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.TANK.0.DHZ  | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.TANK.10.DD1 | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.TANK.10.DD2 | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.TANK.10.DD3 | 2016-04-08T20:31:31.000000Z - 2016-04-08T20:57:31.000000Z | 250.0 Hz, 390001 samples\n",
      "Processing launch at 2016-05-06 05:21:00\n",
      "0 Trace(s) in Stream:\n",
      "\n",
      "Processing launch at 2016-05-27 21:39:00\n",
      "FL/\n",
      "    BCHH/\n",
      "        00/DHE\n",
      "        00/DHN\n",
      "        00/DHZ\n",
      "        10/DD1\n",
      "        10/DD2\n",
      "        10/DD3\n",
      "    SCMN/\n",
      "        0/DHE\n",
      "        0/DHN\n",
      "        0/DHZ\n",
      "        10/DD1\n",
      "        10/DD2\n",
      "        10/DD3\n",
      "12 Trace(s) in Stream:\n",
      "FL.BCHH.00.DHE | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.00.DHN | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.00.DHZ | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.10.DD1 | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.10.DD2 | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.10.DD3 | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.SCMN.0.DHE  | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.SCMN.0.DHN  | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.SCMN.0.DHZ  | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.SCMN.10.DD1 | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.SCMN.10.DD2 | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.SCMN.10.DD3 | 2016-05-27T21:27:00.000000Z - 2016-05-27T21:53:00.000000Z | 250.0 Hz, 390001 samples\n",
      "Processing launch at 2016-06-11 17:51:00\n",
      "FL/\n",
      "    BCHH/\n",
      "        00/DHE\n",
      "        00/DHN\n",
      "        00/DHZ\n",
      "        10/DD1\n",
      "        10/DD2\n",
      "        10/DD3\n",
      "6 Trace(s) in Stream:\n",
      "FL.BCHH.00.DHE | 2016-06-11T17:39:00.000000Z - 2016-06-11T18:05:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.00.DHN | 2016-06-11T17:39:00.000000Z - 2016-06-11T18:05:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.00.DHZ | 2016-06-11T17:39:00.000000Z - 2016-06-11T18:05:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.10.DD1 | 2016-06-11T17:39:00.000000Z - 2016-06-11T18:05:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.10.DD2 | 2016-06-11T17:39:00.000000Z - 2016-06-11T18:05:00.000000Z | 250.0 Hz, 390001 samples\n",
      "FL.BCHH.10.DD3 | 2016-06-11T17:39:00.000000Z - 2016-06-11T18:05:00.000000Z | 250.0 Hz, 390001 samples\n",
      "Processing launch at 2016-06-15 14:29:00\n",
      "0 Trace(s) in Stream:\n",
      "\n",
      "Processing launch at 2016-06-24 14:30:00\n",
      "0 Trace(s) in Stream:\n",
      "\n",
      "Processing launch at 2016-07-18 04:45:29\n",
      "0 Trace(s) in Stream:\n",
      "\n",
      "Processing launch at 2016-07-28 12:37:00\n",
      "0 Trace(s) in Stream:\n",
      "\n",
      "Processing launch at 2016-08-14 05:26:00\n",
      "0 Trace(s) in Stream:\n",
      "\n",
      "Processing launch at 2016-08-19 04:52:00\n",
      "0 Trace(s) in Stream:\n",
      "\n",
      "Processing launch at 2016-09-08 23:05:00\n",
      "0 Trace(s) in Stream:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = launchesDF\n",
    "start_date = obspy.UTCDateTime(2016, 2, 20, 0, 0, 0)\n",
    "end_date = obspy.UTCDateTime(2016, 9, 10, 23, 59, 59)\n",
    "subset_df = df[(df['datetime'] >= start_date) & (df['datetime'] <= end_date)]\n",
    "\n",
    "\n",
    "for idx, eventrow in subset_df.iterrows():\n",
    "    # get start and end time. remember that spreadsheet is in UTC. well data are in local time but summer time is assumed throughout (UTC-4)\n",
    "    launchtimeUTC = eventrow['datetime']\n",
    "\n",
    "    # create event directory\n",
    "    EVENTDIR = os.path.join(paths['WWW_EVENTS'], launchtimeUTC.isoformat())\n",
    "    if not os.path.isdir(EVENTDIR):\n",
    "        os.makedirs(EVENTDIR)  \n",
    "\n",
    "    print('Processing launch at %s' % launchtimeUTC.strftime('%Y-%m-%d %H:%M:%S')) \n",
    "    st = LR.sds2eventStream(launchtimeUTC, sdsclient, thisSDSobj, \\\n",
    "                            pretrig=preseconds+taperseconds, \\\n",
    "                                posttrig=eventseconds+postseconds+taperseconds,\n",
    "                                networks = ['FL', '1R'])\n",
    "\n",
    "    print(st)\n",
    "\n",
    "    continue\n",
    "    # Define the station you want to remove (e.g., 'STATION_NAME')\n",
    "    station_to_remove = \"DWPF\"\n",
    "    #st = st.select(lambda tr: tr.stats.station != station_to_remove)\n",
    "    for tr in st:\n",
    "        if tr.stats.station == station_to_remove:\n",
    "            st.remove(tr)\n",
    "        elif tr.data.size == 0 or all(tr.data == 0):\n",
    "            print(f'- removing {tr.id}')\n",
    "            st.remove(tr)\n",
    "    if len(st)==0:\n",
    "        print('- no Trace objects')\n",
    "        continue\n",
    "    \n",
    "\n",
    "    #st = st.select(network='FL') # while AM, XA, and 1R are also valid, we need to get instrument response data for them\n",
    "\n",
    "    #st = st.filter(lambda trace: trace.data.size > 0 and not all(trace.data == 0))\n",
    "\n",
    "    # all these functions safe for well traces too - if they were in the Stream objects as they were when we converted well data to SDS\n",
    "    \n",
    "    st.plot(equal_scale=False, outfile=os.path.join(EVENTDIR, 'raw.png'));\n",
    "    #LR.clean(st, taperseconds) # despike, detrend, taper, high pass filter, trim\n",
    "    for tr in st:\n",
    "        trace_seconds = tr.stats.delta * tr.stats.npts\n",
    "        libseisGT.clean_trace(tr, taperFraction=taperseconds/trace_seconds, filterType=\"highpass\", freq=0.01, corners=2, zerophase=True, inv=None)\n",
    "    \n",
    "    if len(st)==0:\n",
    "        print('- no Trace objects')\n",
    "        continue\n",
    "    infrasound_st = st.select(channel='[ESBHDG]D?')\n",
    "    #apply_calibration_correction(infrasound_st) \n",
    "    USF_instrument_responses.correctUSFstations(infrasound_st, apply_calib=True, attach=False, return_inventories=False)\n",
    "    #libseisGT.removeInstrumentResponse(infrasound_st, preFilter = None, outputType = \"DISP\", inventory = infrainv)    \n",
    "    LR.detect_incorrect_p2p_voltage_setting(infrasound_st)\n",
    "\n",
    "    seismic_st = st.select(channel='[ESBHDG]H?')\n",
    "    velocity_st = seismic_st.copy()\n",
    "    #velocity_st = remove_response(seismic_st, output='VEL')\n",
    "    libseisGT.removeInstrumentResponse(velocity_st, preFilter = None, outputType = \"VEL\", inventory = inv)\n",
    "    LR.detect_incorrect_p2p_voltage_setting(velocity_st) \n",
    "\n",
    "    # write corrected event out\n",
    "    #correctedfile =  os.path.join(EVENTDIR, '%s.pkl' % launchtimeUTC.strftime('%Y%m%dT%H%M%S'))\n",
    "    #st.write(correctedfile, format='PICKLE') \n",
    "\n",
    "    best_trig = LR.detectEvent(infrasound_st + velocity_st) # + displacement_st)\n",
    "    pad_secs = 10\n",
    "    trigtime = launchtimeUTC\n",
    "    duration = eventseconds\n",
    "    if len(best_trig)>0:    \n",
    "        trigtime = best_trig['time']\n",
    "        duration = best_trig['duration']\n",
    "    trimtime0 = LR.floor_minute(trigtime-pad_secs)\n",
    "    trimtime1 = LR.ceil_minute(trigtime+duration+pad_secs)\n",
    "    infrasound_st.trim(starttime=trimtime0, endtime=trimtime1)\n",
    "    velocity_st.trim(starttime=trimtime0, endtime=trimtime1)\n",
    "    displacement_st = seismic_st.copy()\n",
    "    #displacement_st = remove_response(seismic_st, output='DISP')\n",
    "    libseisGT.removeInstrumentResponse(displacement_st, preFilter = None, outputType = \"DISP\", inventory = inv)\n",
    "    LR.detect_incorrect_p2p_voltage_setting(displacement_st) \n",
    "    displacement_st.trim(starttime=trimtime0, endtime=trimtime1)\n",
    "\n",
    "    # SCAFFOLD\n",
    "    # generate seismic and infrasound figures - but change to add RSAM pandas plots, spectrograms and spectra, etc.\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Set a custom figure size (width, height)\n",
    "    infrasound_st.plot(fig=fig, equal_scale=False, outfile=os.path.join(EVENTDIR, 'infrasound.png'));\n",
    "    fh,axh=libseisGT.mulplt(infrasound_st, bottomlabel='', ylabels=[], MAXPANELS=6)\n",
    "    fh.savefig(fname=os.path.join(EVENTDIR, 'infrasound2.png'))\n",
    "    '''\n",
    "    #super_stream_plot(velocity_st, dpi=100, Nmax=6, rank='ZFODNE123456789', equal_scale=False, outfile=os.path.join(EVENTDIR, 'velocity.png'))\n",
    "    #super_stream_plot(displacement_st, dpi=100, Nmax=6, rank='ZFODNE123456789', equal_scale=False, outfile=os.path.join(EVENTDIR, 'displacement.png'))\n",
    "    if len(infrasound_st)>0:\n",
    "        print('- plotting infrasound')\n",
    "        LR.plot_seismograms(infrasound_st, outfile=os.path.join(EVENTDIR, 'infrasound.png'), bottomlabel=None, ylabels=None, units='Pa', channels='F123456789')\n",
    "    if len(velocity_st)>0:\n",
    "        print('- plotting seismic')\n",
    "        LR.plot_seismograms(velocity_st, outfile=os.path.join(EVENTDIR, 'velocity.png'), bottomlabel=None, ylabels=None, units='m/s')\n",
    "        LR.plot_seismograms(displacement_st, outfile=os.path.join(EVENTDIR, 'displacement.png'), bottomlabel=None, ylabels=None, units='m')\n",
    "    #plot_envelope2(infrasound_st, outfile=os.path.join(EVENTDIR, 'infrasound5.png'), units='Pa')\n",
    "    #plot_envelope2(velocity_st.select(channel='HHZ'), outfile=os.path.join(EVENTDIR, 'velocity2.png'), units='m/s')\n",
    "    #plot_envelope2(displacement_st.select(channel='HHZ'), outfile=os.path.join(EVENTDIR, 'displacement2.png'), units='m')\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Set a custom figure size (width, height)\n",
    "    velocity_st.plot(fig=fig, equal_scale=False, outfile=os.path.join(EVENTDIR, 'velocity.png'));\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Set a custom figure size (width, height)\n",
    "    displacement_st.plot(fig=fig, equal_scale=False, outfile=os.path.join(EVENTDIR, 'displacement.png'));    \n",
    "    # Optionally, set the aspect ratio (e.g., 2:1 aspect ratio)\n",
    "    #ax.set_aspect(2.0)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "passoft3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
