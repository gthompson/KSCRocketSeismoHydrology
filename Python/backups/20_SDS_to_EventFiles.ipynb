{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa61b50-55bf-436b-94a2-92496ad51da7",
   "metadata": {},
   "source": [
    "# Segment SDS Archive based on launch event times and generate event web browser\n",
    "\n",
    "Launch times come from 'PilotStudy_KSC_Rocket_Launches.xlsx'\n",
    "SDS archives are at SDS_TOP and contain data from wells 6I and 6S and from seismo-acoustic stations\n",
    "Segmented event waveform files are saved as MiniSEED to EVENT_WAVEFORMS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473a452-8797-47a4-9f49-8a39cd522fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run header.ipynb\n",
    "HTML_DIR = '/var/www/html/thompsong/KSC_EROSION/EVENTS'\n",
    "PNG_DIR = os.path.join(HTML_DIR, 'images')\n",
    "EVENT_WAVEFORMS = os.path.join(paths['outdir'], 'EVENTS') # must exist, and Excel file must be here\n",
    "csv_launches = os.path.join(paths['outdir'], 'PilotStudy_KSC_Rocket_Launches.csv')\n",
    "csv_launches_detected = os.path.join(paths['outdir'], 'PilotStudy_KSC_Rocket_Launches_detected.csv')\n",
    "\n",
    "\n",
    "def event_sds2pkl(launchtime, thisSDSobj, EVENT_WAVEFORMS, pretrig=3600, posttrig=3600, overwrite=False):    \n",
    "    rawfile = os.path.join(EVENT_WAVEFORMS, '%s_raw.pkl' % launchtime.strftime('%Y%m%dT%H%M%S'))\n",
    "    if os.path.exists(rawfile) and not overwrite:\n",
    "        print('%s already exists' % rawfile)\n",
    "    else:\n",
    "        print('segmenting %s from SDS' % rawfile) \n",
    "        startt = launchtime - pretrig\n",
    "        endt = launchtime + posttrig\n",
    "        thisSDSobj.read(startt, endt, speed=1)\n",
    "        st = thisSDSobj.stream\n",
    "        st.merge(method=0,fill_value=0)\n",
    "\n",
    "        if len(st)>0:\n",
    "            try:\n",
    "                st.write(rawfile, format='pickle')\n",
    "            except:\n",
    "                st2 = Stream()\n",
    "                for tr in st:\n",
    "                    try:\n",
    "                        tr.write('tmp.pkl', 'pickle')\n",
    "                        st2.append(tr)\n",
    "                    except:\n",
    "                        print('Failed:\\n',tr)\n",
    "                print(st2)\n",
    "                if len(st2)>0:\n",
    "                    st2.write(rawfile, format='pickle')\n",
    "                #print('Failed to write raw file')\n",
    "                #print(st)\n",
    "                #rawfile = None\n",
    "        else:\n",
    "            print('Got no data')\n",
    "            rawfile = None\n",
    "    return rawfile\n",
    "\n",
    "def clean(st):\n",
    "    for tr in st:\n",
    "        if tr.stats.network != 'FL':\n",
    "            continue\n",
    "        tr.detrend('linear')\n",
    "        tr.filter('highpass', freq=0.2, corners=2) \n",
    "        \n",
    "def apply_calibration_correction(st):\n",
    "    # calibration correction\n",
    "\n",
    "    for tr in st:\n",
    "        if 'countsPerUnit' in tr.stats:\n",
    "            continue\n",
    "        else:\n",
    "            tr.stats['countsPerUnit'] = 1\n",
    "            if not 'units' in tr.stats:\n",
    "                tr.stats['units'] = 'Counts'\n",
    "            if tr.stats.network[0] =='6': # well data\n",
    "                if tr.stats.channel[2] == 'D':\n",
    "                    tr.stats.countsPerUnit = 1/LLE.psi2inches(1) # counts (psi) per inch\n",
    "                    tr.stats.units = 'inches'\n",
    "                elif tr.stats.channel[2] == 'H':\n",
    "                    tr.stats.countsPerUnit = 1/6894.76 # counts (psi) per Pa\n",
    "                    tr.stats.units = 'Pa'\n",
    "            elif tr.stats.channel[1]=='D':\n",
    "                tr.stats.countsPerUnit = 720 # counts/Pa on 1 V FS setting\n",
    "                if tr.id[:-1] == 'FL.BCHH3.10.HD':\n",
    "                    if tr.stats.starttime < UTCDateTime(2022,5,26): # Chaparral M25. I had it set to 1 V FS. Should have used 40 V FS. \n",
    "                        if tr.id == 'FL.BCHH3.10.HDF':\n",
    "                            tr.stats.countsPerUnit = 8e5 # counts/Pa\n",
    "                        else:\n",
    "                            tr.stats.countsPerUnit = 720 # counts/Pa \n",
    "                    else: # Chaparral switched to 40 V FS\n",
    "                        if tr.id == 'FL.BCHH3.10.HDF':\n",
    "                            tr.stats.countsPerUnit = 2e4 # counts/Pa\n",
    "                        else:\n",
    "                            tr.stats.countsPerUnit = 18 # counts/Pa \n",
    "                tr.stats.units = 'Pa'\n",
    "\n",
    "            elif tr.stats.channel[1]=='H':\n",
    "                tr.stats.countsPerUnit = 3e2 # counts/(um/s)\n",
    "                tr.stats.units = 'um/s'\n",
    "            tr.data = tr.data/tr.stats.countsPerUnit\n",
    "    \n",
    "def maxamp(tr):\n",
    "    return np.max(np.abs(tr.data))\n",
    "\n",
    "def remove_spikes(st):\n",
    "    SEISMIC_MAX = 0.1 # m/s\n",
    "    INFRASOUND_MAX = 3000 # Pa\n",
    "    FEET_MAX = 21 # feet\n",
    "    #SEISMIC_MIN = 1e-9\n",
    "    #INFRASOUND_MIN = 0.01\n",
    "    \n",
    "    for tr in st:\n",
    "        ma = maxamp(tr)\n",
    "        if tr.stats.units == 'm/s':\n",
    "            tr.data[tr.data > SEISMIC_MAX] = np.nan\n",
    "            tr.data[tr.data < -1 * SEISMIC_MAX] = np.nan             \n",
    "        elif tr.stats.units == 'Pa':\n",
    "            tr.data[tr.data > INFRASOUND_MAX] = np.nan\n",
    "            tr.data[tr.data < -1 * INFRASOUND_MAX] = np.nan   \n",
    "        elif tr.stats.units == 'feet':\n",
    "            tr.data[tr.data > FEET_MAX] = np.nan\n",
    "            tr.data[tr.data < -1 * FEET_MAX] = np.nan               \n",
    "\n",
    "from obspy.signal.trigger import coincidence_trigger\n",
    "from pprint import pprint\n",
    "import matplotlib.dates as dates\n",
    "def detectEvent(st, launchtime):\n",
    "    trig = coincidence_trigger(\"recstalta\", 3.5, 1, st, 3, sta=2, lta=40)\n",
    "    best_trig = {}\n",
    "    best_product = 0\n",
    "    for this_trig in trig:\n",
    "        thistime = dates.date2num(this_trig['time'])\n",
    "        this_product = this_trig['coincidence_sum']*this_trig['duration']\n",
    "        if this_product > best_product:\n",
    "            best_trig = this_trig\n",
    "            best_product = this_product\n",
    "    pprint(best_trig)\n",
    "    return best_trig['time']\n",
    "\n",
    "'''\n",
    "def add_snr(st, assoctime, threshold=1.5):\n",
    "    nstime = max([st[0].stats.starttime, assoctime-240])\n",
    "    netime = min([st[0].stats.endtime, assoctime-60])\n",
    "    sstime = assoctime\n",
    "    setime = min([st[0].stats.endtime, assoctime+120])    \n",
    "    for tr in st:\n",
    "        tr_noise = tr.copy().trim(starttime=nstime, endtime=netime)\n",
    "        tr_signal = tr.copy().trim(starttime=sstime, endtime=setime)\n",
    "        tr.stats['noise'] = np.nanmedian(np.abs(tr_noise.data))\n",
    "        tr.stats['signal'] = np.nanmedian(np.abs(tr_signal.data))\n",
    "        tr.stats['snr'] = tr.stats['signal']/tr.stats['noise']\n",
    "        '''\n",
    "\n",
    "def group_streams_for_plotting(st):\n",
    "    groups = {}\n",
    "    stationsWELL = ['6S', '6I']\n",
    "    for station in stationsWELL:\n",
    "        stationStream = st.select(network=station)\n",
    "        #stationIDS = list(set([tr.id for tr in stationStream]))\n",
    "        groups[station] = stationStream\n",
    "    streamSA = st.select(network='FL')\n",
    "    stationsSA = list(set([tr.stats.station for tr in streamSA]))\n",
    "    for station in stationsSA:\n",
    "        stationStream = streamSA.select(station=station)\n",
    "        #stationIDS = list(set([tr.id for tr in stationStream]))\n",
    "        groups[station] = stationStream\n",
    "    #print(groups)\n",
    "    return groups  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bccb83",
   "metadata": {},
   "source": [
    "## 2. For each launch, segment raw SDS data to multi-trace MiniSEED file in EVENT_WAVEFORMS directory\n",
    "## 1. Read launch data into a DataFrame and generate a list of launch times in Python datetime.datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e576745-3187-4e67-86f0-21fb550578e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "startover = True # starts with original CSV file again\n",
    "if os.path.isfile(csv_launches_detected) and startover==False:\n",
    "    launchesDF = LLE.removed_unnamed_columns(pd.read_csv(csv_launches_detected, index_col=None))\n",
    "else:\n",
    "    launchesDF = LLE.removed_unnamed_columns(pd.read_csv(csv_launches, index_col=None))\n",
    "    dt_tmp = pd.to_datetime(launchesDF['Date'] + ' ' +  launchesDF['Time'])\n",
    "    launchesDF['Date'] = [pdt.to_pydatetime() for pdt in dt_tmp]\n",
    "    launchesDF.drop(labels='Time', axis=1, inplace=True)\n",
    "    del dt_tmp\n",
    "\n",
    "for thisdir in [EVENT_WAVEFORMS, HTML_DIR, PNG_DIR]:\n",
    "    if not os.path.isdir(thisdir):\n",
    "        os.makedirs(thisdir)\n",
    "\n",
    "if not 'rawfile' in launchesDF.columns:\n",
    "    launchesDF['rawfile'] = None\n",
    "if not 'corrected_file' in launchesDF.columns: \n",
    "    launchesDF['corrected_file'] = None \n",
    "if not 'detected' in launchesDF.columns:\n",
    "    launchesDF['detection_time'] = None \n",
    "if not 'short_file' in launchesDF.columns:\n",
    "    launchesDF['short_file'] = None \n",
    "launchesDF.to_csv(csv_launches_detected) \n",
    "\n",
    "\n",
    "thisSDSobj = SDS.SDSobj(paths['SDS_TOP'])\n",
    "for i, row in launchesDF.iterrows():\n",
    "    launchTime = UTCDateTime(row['Date'])\n",
    "    print('Processing launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S'))                        \n",
    "    if not row['corrected_file']:\n",
    "        if row['rawfile']:\n",
    "            rawfile = os.path.join(EVENT_WAVEFORMS, row['rawfile'])\n",
    "        else:\n",
    "            rawfile = event_sds2pkl(launchTime, thisSDSobj, EVENT_WAVEFORMS, overwrite=False)\n",
    "            if rawfile:\n",
    "                launchesDF.at[i, 'rawfile'] = os.path.basename(rawfile)\n",
    "            else:\n",
    "                raise Exception('failed to create %s' % rawfile)\n",
    "        try:\n",
    "            st = read(rawfile)    \n",
    "            #st.merge(method=0, fill_value=0)\n",
    "        except:\n",
    "            st = Stream()\n",
    "        print('%s: %d channels' % (rawfile,len(st)))\n",
    "\n",
    "        # all these functions safe for well traces too\n",
    "        clean(st) \n",
    "        apply_calibration_correction(st)\n",
    "        remove_spikes(st)\n",
    "        \n",
    "        # write corrected event out\n",
    "        correctedfile =  os.path.join(EVENT_WAVEFORMS, '%s_long.pkl' % launchTime.strftime('%Y%m%dT%H%M%S'))\n",
    "        print('Writing %s' % correctedfile)\n",
    "        try:\n",
    "            st.write(correctedfile, format='PICKLE') # save 2-hour event waveforms\n",
    "            launchesDF.at[i, 'corrected_file'] = os.path.basename(correctedfile)\n",
    "        except:\n",
    "            pass\n",
    "del thisSDSobj\n",
    "launchesDF.to_csv(csv_launches_detected) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b733e7-98b5-409e-8991-da2d47ff4caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Detecting events')            \n",
    "for i, row in launchesDF.iterrows():\n",
    "    launchTime = UTCDateTime(row['Date'])\n",
    "    if row['corrected_file']:\n",
    "        correctedfile =  os.path.join(EVENT_WAVEFORMS, row['corrected_file'])\n",
    "    else:\n",
    "        continue\n",
    "    print('Detecting launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S'))                        \n",
    "    if not row['detection_time']:  \n",
    "        # subset out the seismo-acoustic traces for detection purposes\n",
    "        if not os.path.isfile(correctedfile):\n",
    "            print('File not found: ',correctedfile)\n",
    "            continue\n",
    "        st = read(correctedfile)\n",
    "        SA = st.copy().select(network='FL').trim(starttime=launchTime-100, endtime=launchTime+200)\n",
    "        if len(SA)==0:\n",
    "            continue\n",
    "\n",
    "        assocTime = detectEvent(SA, launchTime)\n",
    "            \n",
    "        if abs(assocTime-launchTime)>100:\n",
    "            assocTime=launchTime\n",
    "        launchesDF.at[i, 'detection_time'] = assocTime\n",
    "launchesDF.to_csv(csv_launches_detected) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52bfe85-6ec5-4a53-b8f6-463924e6c999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Creating short files')\n",
    "overwrite=True\n",
    "for i, row in launchesDF.iterrows():\n",
    "    launchTime = UTCDateTime(row['Date']) \n",
    "    print('- Processing launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S'))                        \n",
    "    if not row['short_file'] or overwrite:\n",
    "        if row['corrected_file']:\n",
    "            correctedfile =  os.path.join(EVENT_WAVEFORMS, row['corrected_file'])\n",
    "        else:\n",
    "            continue   \n",
    "        if not os.path.isfile(correctedfile):\n",
    "            print('File not found: ',correctedfile)\n",
    "            continue\n",
    "        # save 3-minute event waveforms\n",
    "        st = read(correctedfile)\n",
    "        if len(st)==0:\n",
    "            continue\n",
    "\n",
    "        assocTime = row['detection_time']\n",
    "        if not assocTime:\n",
    "            continue\n",
    "        st_short = st.copy()\n",
    "        st_short.filter('highpass', freq=0.1, corners=2)\n",
    "        st_short.trim(starttime=assocTime-30, endtime=assocTime+150)\n",
    "        print(st_short)\n",
    "        if len(st_short)>0:\n",
    "            # write shorter corrected event out\n",
    "            shortfile =  os.path.join(EVENT_WAVEFORMS, '%s_short.pkl' % launchTime.strftime('%Y%m%dT%H%M%S'))\n",
    "            print('Writing %s' % shortfile)\n",
    "            try:\n",
    "                st_short.write(shortfile, format='PICKLE') # save 2-hour event waveforms\n",
    "            except:\n",
    "                pass\n",
    "            launchesDF.at[i, 'short_file'] = os.path.basename(shortfile)\n",
    "launchesDF.to_csv(csv_launches_detected)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce159c6-f625-4892-8f86-f5f83d86344d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Plotting')\n",
    "for i, row in launchesDF.iterrows():\n",
    "    launchTime = UTCDateTime(row['Date'])\n",
    "    print('- Plotting launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S')) \n",
    "    for ext in ['long', 'short']:\n",
    "        if ext=='short':\n",
    "            pklfile = row['short_file']\n",
    "        else:    \n",
    "            pklfile = row['corrected_file']\n",
    "        if not pklfile:\n",
    "            continue\n",
    "        pklfile = os.path.join(EVENT_WAVEFORMS, pklfile)\n",
    "        if not os.path.isfile(pklfile):\n",
    "            print('File not found: ',pklfile)\n",
    "            continue\n",
    "        st = read(pklfile)\n",
    "        if len(st)==0:\n",
    "            continue        \n",
    "        groups = group_streams_for_plotting(st)\n",
    "        for station, stream_group in groups.items():\n",
    "            if len(stream_group)>0:\n",
    "                pngfile = os.path.join(PNG_DIR, '%s_%s_%s.png' % (launchTime.strftime('%Y%m%dT%H%M%S'), station, ext))\n",
    "                stream_group.plot(equal_scale=False, outfile=pngfile)\n",
    "\n",
    "launchesDF.to_csv(csv_launches_detected)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309596f2-eef4-47cb-8634-d3c0350651a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_event_html(i, row, stations, ext='short',peakmeas=None,units=None):\n",
    "    launchTime = UTCDateTime(row['Date'])    \n",
    "    lts = launchTime.strftime('%Y%m%dT%H%M%S')\n",
    "    lts_human = launchTime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    htmlfile = os.path.join(HTML_DIR, 'launch_%s_%s.html' % (lts, ext))\n",
    "    nl = '\\n'\n",
    "    print(f\"Writing {htmlfile}\")\n",
    "    contents = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>\"\"\"\n",
    "    contents = f\"Event {lts_human}</title>\\n</head>\\n\\n<body>{nl}\"\n",
    "\n",
    "    # EVENT INFO\n",
    "    contents += \"<table border=1>\\n\"\n",
    "    contents += f\"<tr> <th>Event Number:</th> <td>{i}</td> </tr>\\n\"\n",
    "    contents += f\"<tr> <th>Date/Time:</th> <td>{lts_human} {launchTime.timestamp,} ({launchTime.strftime('%j')}) </td> </tr>{nl}\"\n",
    "    contents += f\"<tr> <th>Detection time:</th> <td>{row['detection_time']}</td> </tr>{nl}\"\n",
    "    contents += f\"<tr> <th>Rocket/Payload:</th> <td>{row['Rocket_Payload']}</td> </tr>{nl}\"\n",
    "    contents += f\"<tr> <th>Launchpad:</th> <td>{row['SLC']}</td> </tr>{nl}\"\n",
    "    contents += f\"<tr> <th>Notes:</th> <td>{row['Notes']}</td> </tr>{nl}\"\n",
    "    contents += \"</table>\\n\"\n",
    "\n",
    "    # PEAK MEASUREMENTS\n",
    "    if peakmeas:\n",
    "        contents += \"<table border=1>\\n<tr>\"\n",
    "        for id in peakmeas.keys():\n",
    "            contents += f\"<th>{id}</th>\"\n",
    "        contents += \"</tr>\\n<tr>\"\n",
    "        for id in peakmeas.keys():\n",
    "            thispeakstr = '%.2e' % peakmeas[id]\n",
    "            contents += f\"<td>{thispeakstr}, {units[id]}</td>\"      \n",
    "        contents += \"</tr>\\n<\\table>\\n\"           \n",
    "    \n",
    "\n",
    "    # PLOTS\n",
    "    contents += \"<table border=1>\\n\"\n",
    "    for station in stations:\n",
    "        pngfile = os.path.join(os.path.basename(PNG_DIR), '%s_%s_%s.png' % (lts, station, ext))\n",
    "        contents += f\"<tr> <td><h1>{station}</h1></td> <td><a href='{pngfile}'><img src='{pngfile}'></a><td/> </tr> {nl}\"\n",
    "    contents += \"</table>\\n\"\n",
    "    \n",
    "    contents += \"</body>\\n</html>\"\n",
    "    fptr = open(htmlfile, \"w\")\n",
    "    fptr.write(contents)\n",
    "    fptr.close()\n",
    "    #print(contents)\n",
    "    return os.path.basename(htmlfile)\n",
    "\n",
    "def make_index_html(launchesDF):\n",
    "    contents0 = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>Events</title>\n",
    "</head>\n",
    "<body>\n",
    "<table border=1>\n",
    "<tr><th>Date</th><th>Rocket/Payload</th><th>Launchpad</th><th>Short</th><th>Long</th><th>Strength (um/s)</th></tr>\n",
    "    \"\"\"    \n",
    "    for i, row in launchesDF.iterrows():\n",
    "\n",
    "        print(i, 'of ', len(launchesDF) )\n",
    "\n",
    "        launchTime = UTCDateTime(row['Date'])    \n",
    "        lts = launchTime.strftime('%Y%m%dT%H%M%S')\n",
    "        lts_human = launchTime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        contents0 += f\"<tr> <td>{lts_human} ({launchTime.timestamp,} {launchTime.strftime('%j')}) </td> \"\n",
    "        contents0 += f\"<td>{row['Rocket_Payload']}</td> <td>{row['SLC']}</td> \"\n",
    "\n",
    "        HHZpeak = 0 \n",
    "        for ext in ['short', 'long']:\n",
    "            if ext=='short':\n",
    "                pklfile = row['short_file']\n",
    "            else:    \n",
    "                pklfile = row['corrected_file']\n",
    "            if not pklfile:\n",
    "                continue\n",
    "            pklfile =  os.path.join(EVENT_WAVEFORMS, pklfile)\n",
    "            print('pklfile=',pklfile) \n",
    "            if os.path.isfile(pklfile):\n",
    "                st = read(pklfile, 'PICKLE')\n",
    "                groups = group_streams_for_plotting(st)\n",
    "                peakmeas = dict()\n",
    "                units = dict()\n",
    "                if ext=='short':\n",
    "                    for tr in st:\n",
    "                        peakmeas[tr.id] = max(abs(tr.data)) \n",
    "                        units[tr.id] = tr.stats.units\n",
    "                        if tr.stats.channel == 'HHZ':\n",
    "                            if peakmeas[tr.id] > HHZpeak:\n",
    "                                HHZpeak = peakmeas[tr.id]\n",
    "                stations = groups.keys()\n",
    "                htmlfile = make_event_html(i, row, stations, ext, peakmeas, units)\n",
    "                contents0 += f\"<td><a href={htmlfile}>{ext}</a></td> \"\n",
    "            else:\n",
    "                contents0 += f\"<td>None</td> \"\n",
    "        HHZpeakstr = '%.2e' % HHZpeak\n",
    "        contents0 += f\"<td>{HHZpeakstr}</td> </tr>\"\n",
    "        contents0 += '\\n'\n",
    "    contents0 += \"\\n</table>\\n</body>\\n</html>\"\n",
    "    indexfile = os.path.join(HTML_DIR, 'index.html')\n",
    "    fptr0 = open(indexfile, \"w\")\n",
    "    fptr0.write(contents0)\n",
    "    fptr0.close()    \n",
    "\n",
    "\n",
    "#make_html(UTCDateTime('2022-11-03 05:22:00'), ['S39A1', 'BCHH2'])\n",
    "#print(launchesDF)\n",
    "make_index_html(launchesDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463bf10",
   "metadata": {},
   "source": [
    "## 3. Generate HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexfile = open(os.path.join(HTML_DIR, \"index.html\"), \"w\")\n",
    "print(f\"Writing {indexfile}\")\n",
    "indexfile.write(\"\"\"\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "<title>Launch data browser</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "<table border=1>\n",
    "\n",
    "<tr>\n",
    "<th>Launch time</th>\n",
    "<th>JulDay</th>\n",
    "<th>epoch</th>\n",
    "<th>Seismic</th>\n",
    "<th>Infrasound</th>\n",
    "<th>Well_6S</th>\n",
    "<th>Well_6I</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "for i, row in launchesDF.iterrows():\n",
    "    print('\\n\\n\\n')\n",
    "    launchTime = UTCDateTime(row['Date'])\n",
    "    print('Processing launch at %s' % launchTime.strftime('%Y-%m-%d %H:%M:%S'))  \n",
    "    indexfile.write(\"<td>%s</td>\\n<td>%s</td>\\n<td>%.0f</td>\\n\" % (launchTime, launchTime.julday, launchTime.timestamp))\n",
    "    \n",
    "    ## Seismic\n",
    "    correctedfile =  os.path.join(EVENT_WAVEFORMS, 'launch_%s_corrected.pkl' % launchTime.strftime('%Y%m%dT%H%M%S'))\n",
    "    seismicpngfile = os.path.join(PNG_DIR, 'launch_%s_seismic.png' % launchTime.strftime('%Y%m%dT%H%M%S') )\n",
    "    if not os.path.exists(seismicpngfile):\n",
    "        print('Reading %s' % correctedfile)\n",
    "        try:\n",
    "            st = read(correctedfile, format='PICKLE')\n",
    "        except:\n",
    "            st = Stream()\n",
    "        st_seismic = st.select(channel='HH?').select(network='FL')\n",
    "        if len(st_seismic)>0:\n",
    "            st_seismic.plot(equal_scale=False, outfile=seismicpngfile )            \n",
    "    if os.path.exists(seismicpngfile):\n",
    "        st_seismic = read(correctedfile, format='PICKLE').select(channel='HH?').select(network='FL')\n",
    "        indexfile.write(\"<td><a href=\\'%s\\'>%d</a></td>\\n\" % (os.path.basename(seismicpngfile), len(st_seismic)))\n",
    "    else:\n",
    "        indexfile.write(\"<td>0</td>\\n\")\n",
    "        \n",
    "    ## Acoustic\n",
    "    acousticpngfile = os.path.join(PNG_DIR, 'launch_%s_infrasound.png' % launchTime.strftime('%Y%m%dT%H%M%S') )\n",
    "    if not os.path.exists(acousticpngfile):\n",
    "        if not st: # in locals():\n",
    "            print('Reading %s' % correctedfile)\n",
    "            try:\n",
    "                st = read(correctedfile, format='PICKLE')\n",
    "            except:\n",
    "                st = Stream()\n",
    "        st_acoustic = st.select(channel='HD?').select(network='FL')\n",
    "        \n",
    "        if len(st_acoustic)>0: \n",
    "            st_acoustic.plot(equal_scale=False, outfile=acousticpngfile )\n",
    "    if os.path.exists(acousticpngfile): \n",
    "        st_acoustic = read(correctedfile, format='PICKLE').select(channel='HD?').select(network='FL')\n",
    "        indexfile.write(\"<td><a href=\\'%s\\'>%d</a></td>\\n\" % (os.path.basename(acousticpngfile), len(st_acoustic) ))\n",
    "    else:\n",
    "        indexfile.write(\"<td>0</td>\\n\")    \n",
    "         \n",
    "    # Well 6S\n",
    "    for well in ['6S', '6I']:\n",
    "        wellpngfile = os.path.join(PNG_DIR, 'launch_%s_well_%s.png' % (launchTime.strftime('%Y%m%dT%H%M%S'), well) )\n",
    "        if not os.path.exists(wellpngfile):\n",
    "            if not 'st': # in locals():\n",
    "                print('Reading %s' % correctedfile)\n",
    "                try:\n",
    "                    st = obspy.read(correctedfile)\n",
    "                except:\n",
    "                    st = Stream()\n",
    "            st_well = st.select(network=well)\n",
    "            if len(st_well)>0: \n",
    "                st_well.plot(equal_scale=False, outfile=wellpngfile )\n",
    "        if os.path.exists(wellpngfile):   \n",
    "            st_well = read(correctedfile, format='PICKLE').select(network=well)\n",
    "            indexfile.write(\"<td><a href=\\'%s\\'>%d</a></td>\\n\" % (os.path.basename(wellpngfile), len(st_well)))\n",
    "        else:\n",
    "            indexfile.write(\"<td>0</td>\\n\")              \n",
    "\n",
    "        \n",
    "    # comments\n",
    "    #indexfile.write(\"<td>%s</td>\\n\" % launchcomments[launchnum])\n",
    "    \n",
    "    # end this row of table\n",
    "    indexfile.write(\"</tr>\\n\\n\")\n",
    "\n",
    "indexfile.write(\"\"\"\n",
    "\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "\"\"\")\n",
    "indexfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0729dbc7",
   "metadata": {},
   "source": [
    "# 4. Generate event browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "launchpngs = sorted(glob.glob(os.path.join(HTML_DIR, \"*_seismic.png\")))\n",
    "    \n",
    "htmlstr = '''\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Launch Events</title>\n",
    "\n",
    "    <!-- Basic style -->\n",
    "    <style>\n",
    "        .img-container {\n",
    "            margin: 20px auto;\n",
    "            width: 40%%;\n",
    "        }\n",
    "\n",
    "        .btn-container {\n",
    "            text-align: center;\n",
    "        }\n",
    "\n",
    "        img {\n",
    "            width: 600px;\n",
    "            display: block;\n",
    "            margin: auto;\n",
    "            padding-bottom: 20px;\n",
    "        }\n",
    "\n",
    "        button {\n",
    "            outline: none;\n",
    "            padding: 12px;\n",
    "            border: none;\n",
    "            background-color: rgb(25, 121, 211);\n",
    "            border-radius: 8px;\n",
    "            color: white;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "    </style>\n",
    "\n",
    "</head>\n",
    "<body>\n",
    "    <!-- HTML code for next and previous button -->\n",
    "    <div class=\"img-container\">\n",
    "'''\n",
    "htmlstr += f\"<h1 id='imageTitle'>{os.path.basename(launchpngs[0])} </h1>\"\n",
    "htmlstr += f\"<img src='{os.path.basename(launchpngs[0])}' class='imageTag'>\"\n",
    "htmlstr += '''\n",
    "        <div class=\"btn-container\">\n",
    "            <button onclick=\"previous()\">Previous</button>\n",
    "            <button onclick=\"next()\">Next</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <!-- Javascript code for next and previous button -->\n",
    "    <script>\n",
    "        let images = [\n",
    "'''\n",
    "for launchpng in launchpngs:\n",
    "    htmlstr += f\"'{os.path.basename(launchpng)}',\"\n",
    "htmlstr += '''\n",
    "        ];\n",
    "        let imageTag = document.querySelector('.imageTag');\n",
    "        var heading = document.getElementById('heading');\n",
    "    \n",
    "        let i = 0;\n",
    "\n",
    "        function next() {\n",
    "            if (i >= images.length - 1) {\n",
    "                return false;\n",
    "            }\n",
    "            i++;\n",
    "            imageTag.setAttribute('src', images[i]);\n",
    "            imageTitle.textContent = images[i];\n",
    "        }\n",
    "        function previous() {\n",
    "            if (i <= 0) {\n",
    "                return false;\n",
    "            }\n",
    "            i--;\n",
    "            imageTag.setAttribute('src', images[i]);\n",
    "            imageTitle.textContent = images[i];\n",
    "        }\n",
    "\n",
    "    </script>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "'''\n",
    "\n",
    "with open(os.path.join(HTML_DIR,\"launches.html\"), \"w\") as text_file:\n",
    "    text_file.write(htmlstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa78897",
   "metadata": {},
   "source": [
    "Modify above so that it looks for seismic, infrasound, and well data PNGs, and moves them all forward at once.\n",
    "Perhaps we save everything to a CSV file - all the file names and any titles, descriptors, etc. Then we can load that into a dataframe.\n",
    "Then within next and previous, we load appropriate row, and update things.\n",
    "Could also have a clickable index in a separate frame to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(launchesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "launchpngs = sorted(glob.glob(os.path.join(HTML_DIR, \"*_seismic.png\")))\n",
    "seismicpngs = []\n",
    "acousticpngs = []\n",
    "wellpngs = []\n",
    "for i, row in launchesDF.iterrows():\n",
    "    launchTime = UTCDateTime(row['Date'])\n",
    "    seismicpngs.append('launch_%s_seismic.png' % launchTime.strftime('%Y%m%dT%H%M%S') )\n",
    "    acousticpngs.append('launch_%s_acoustic.png' % launchTime.strftime('%Y%m%dT%H%M%S') )\n",
    "    wellpngs.append('launch_%s_well.png' % launchTime.strftime('%Y%m%dT%H%M%S') )\n",
    "launchesDF['seismicpngs']=seismicpngs\n",
    "launchesDF['acousticpngs']=acousticpngs\n",
    "launchesDF['wellpngs']=wellpngs\n",
    "ldf = launchesDF.copy()\n",
    "ldf.fillna(\"\",inplace=True)\n",
    "jsonstr = ldf.to_json(orient='columns')\n",
    "#from json import loads, dumps\n",
    "#parsed = loads(jsonDf) # turn json string into dict\n",
    "#jsonstr = dumps(parsed).replace(None, 'null') # python objects to json string\n",
    "\n",
    "#parsed = json.loads(r)\n",
    "#print(dumps(parsed, indent=4))\n",
    "\n",
    "htmlstr = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Launch Events</title>\n",
    "\n",
    "    <!-- Basic style -->\n",
    "    <style>\n",
    "        .img-container {\n",
    "            margin: 20px auto;\n",
    "            width: 40%%;\n",
    "        }\n",
    "\n",
    "        .btn-container {\n",
    "            text-align: center;\n",
    "        }\n",
    "\n",
    "        img {\n",
    "            width: 600px;\n",
    "            display: block;\n",
    "            margin: auto;\n",
    "            padding-bottom: 20px;\n",
    "        }\n",
    "\n",
    "        button {\n",
    "            outline: none;\n",
    "            padding: 12px;\n",
    "            border: none;\n",
    "            background-color: rgb(25, 121, 211);\n",
    "            border-radius: 8px;\n",
    "            color: white;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "    </style>\n",
    "\n",
    "</head>\n",
    "<body>\n",
    "    <!-- HTML code for next and previous button -->\n",
    "    <div class=\"img-container\">\n",
    "'''\n",
    "htmlstr += f\"        <h1 id=\\\"pageTitle\\\">{seismicpngs[0]}</h1>\"\n",
    "htmlstr += f\"<img src=\\\"{seismicpngs[0]}\\\" class=\\\"imageSeismic\\\">\"\n",
    "htmlstr += '''\n",
    "        <div class=\"btn-container\">\n",
    "            <button onclick=\"previous()\">Previous</button>\n",
    "            <button onclick=\"next()\">Next</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <!-- Javascript code for next and previous button -->\n",
    "    <script>\n",
    "    '''\n",
    "\n",
    "#htmlstr += f\"    const jsonObj = JSON.parse({jsonstr});\"\n",
    "htmlstr += f\"    const jsonObj = {jsonstr};\"\n",
    "#htmlstr += f\"    const jsonObj = {parsed};\"\n",
    "#htmlstr +=  \"    console.log(JSON.stringify(jsonObj));\"\n",
    "htmlstr += f\"    const seismicpngs = {seismicpngs};\"\n",
    "htmlstr += \"\"\"\n",
    "\n",
    "        console.log(seismicpngs);\n",
    "        console.log(jsonObj['SLC']);\n",
    "        let result = Object.keys(jsonObj).map(function (key) {\n",
    "            return jsonObj[key];\n",
    "        });\n",
    "        console.log(result);\n",
    "        \n",
    "        let imageSeismic = document.querySelector('.imageSeismic');\n",
    "        var pageTitle = document.getElementById('pageTitle');\n",
    "    \n",
    "        let i = 0;\n",
    "\n",
    "        function next() {\n",
    "            if (i >= seismicpngs.length - 1) {\n",
    "                return false;\n",
    "            }\n",
    "            i++;\n",
    "            imageSeismic.setAttribute('src', seismicpngs[i]);\n",
    "            //pageTitle.textContent = 'seismicpngs[i]';\n",
    "            document.getElementById('pageTitle').innerHTML = seismicpngs[i];\n",
    "        }\n",
    "        function previous() {\n",
    "            if (i <= 0) {\n",
    "                return false;\n",
    "            }\n",
    "            i--;\n",
    "            imageSeismic.setAttribute('src', seismicpngs[i]);\n",
    "            //pageTitle.textContent = 'seismicpngs[i]';\n",
    "            document.getElementById('pageTitle').innerHTML = seismicpngs[i];\n",
    "        }\n",
    "\n",
    "    </script>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(HTML_DIR,\"launches2.html\"), \"w\") as text_file:\n",
    "    text_file.write(htmlstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24483f1e",
   "metadata": {},
   "source": [
    "So currently I am getting my dataframe into some sort of name-value key-value hash in Javascript, but I don't have an easy way to access entire columns. And all I know how to do is take each column as an array, and then index it (as with seismicpngs). Try to find out how to index acousticpngs from Javascript key-value hash.\n",
    "\n",
    "Also need to make RSAM plots where any zeros are turned into NaN. And then a webpage for availability plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(launchesDF.iloc[0]['Date'].strftime('%j'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92759e0-ad64-418a-9367-a6c9cb1cfa3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
