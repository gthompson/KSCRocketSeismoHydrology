{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, obspy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import platform\n",
    "osname = platform.system()\n",
    "print(osname)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(os.path.join(cwd, 'campbell'))\n",
    "#import read_cs_files as campbell\n",
    "\n",
    "if osname=='Darwin':\n",
    "    HOME = os.getenv('HOME')\n",
    "    DROPBOX_TOP = os.path.join(HOME, 'Dropbox')\n",
    "    SDS_TOP = os.path.join(DROPBOX_TOP, 'DATA', 'SDS')\n",
    "    WELLDATA_TOP = os.path.join(DROPBOX_TOP, 'DATA', 'KSC', 'KSC_Well_Seismoacoustic_Data/WellData')\n",
    "    TOB3_DIR = os.path.join(WELLDATA_TOP, 'Uploads')\n",
    "    PKL_DIR = os.path.join(WELLDATA_TOP, 'Converted')\n",
    "elif osname=='Linux':\n",
    "    HOME = os.getenv('HOME')\n",
    "    DROPBOX_TOP = '/raid/newhome/thompsong/Dropbox'\n",
    "    SDS_TOP = os.path.join(HOME, 'SDS')\n",
    "    if not os.path.isdir(SDS_TOP):\n",
    "        os.mkdir(SDS_TOP)\n",
    "    WELLDATA_TOP = os.path.join(DROPBOX_TOP, 'DATA', 'KSC', 'KSC_Well_Seismoacoustic_Data/WellData')\n",
    "    TOB3_DIR = os.path.join(WELLDATA_TOP, 'Uploads')\n",
    "    PKL_DIR = os.path.join(HOME, 'Converted') \n",
    "elif osname=='Windows':\n",
    "    HOME = 'C:\\\\Users\\\\thompsong'\n",
    "    DROPBOX_TOP = 'D:\\\\Dropbox'\n",
    "    SDS_TOP = \"D:\\\\SDS\"\n",
    "    if not os.path.isdir(SDS_TOP):\n",
    "        os.mkdir(SDS_TOP)\n",
    "    WELLDATA_TOP = os.path.join(DROPBOX_TOP, 'DATA', 'KSC', 'KSC_Well_Seismoacoustic_Data', 'WellData')\n",
    "    TOB3_DIR = os.path.join(WELLDATA_TOP, 'Uploads')\n",
    "    PKL_DIR = 'D:\\\\Converted' \n",
    "lookuptable = os.path.join(PKL_DIR,'lookuptable.csv') \n",
    "  \n",
    "#DROPBOX_PROJECT_DIR = os.path.join(DROPBOX_TOP, 'PROFESSIONAL/RESEARCH/3_Project_Documents/NASAprojects/201602 Rocket Seismology/202010 KSC Launchpad Erosion')\n",
    "#EVENT_MSEED_DIR = os.path.join(DROPBOX_TOP, 'DATA', 'KSC', 'KSC_Well_Seismoacoustic_Data/SeismoAcousticData/Events')\n",
    "\n",
    "if not os.path.isdir(PKL_DIR):\n",
    "    os.mkdir(PKL_DIR)\n",
    "\n",
    "print(PKL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2sds(df, sdsobj, transducersDF): # I think df here is supposed to be from a single picklefile\n",
    "    #print('***')\n",
    "    #print(df.columns)  \n",
    "    #print('***')  \n",
    "    local_startt = obspy.UTCDateTime(df.iloc[0]['TIMESTAMP'])\n",
    "    nextt = obspy.UTCDateTime(df.iloc[1]['TIMESTAMP'])\n",
    "    dt = nextt-local_startt\n",
    "    utc_startt = localtime2utc(local_startt)\n",
    "    if utc_startt > obspy.UTCDateTime():\n",
    "        return\n",
    "    print('local ', local_startt, '-> UTC ', utc_startt)\n",
    "    st = obspy.Stream()    \n",
    "    #print('***')\n",
    "    #print(df.columns)    \n",
    "    for col in df.columns[2:]:\n",
    "        print('Processing column %s' % col)\n",
    "        this_transducer = transducersDF[(transducersDF['serial']) == col]\n",
    "        print('***')\n",
    "        print(this_transducer)\n",
    "        print('***')\n",
    "        if len(this_transducer.index)==1:\n",
    "            this_transducer = this_transducer.iloc[0].to_dict()\n",
    "            tr = obspy.Trace()\n",
    "            tr.id = this_transducer['id']\n",
    "            tr.stats.starttime = utc_startt\n",
    "            tr.stats.delta = dt  \n",
    "            tr.data = np.array(df[col])           \n",
    "            print(f\"sampling rate = {tr.stats.sampling_rate}\")\n",
    "            if int(tr.stats.sampling_rate)==20:\n",
    "                if tr.stats.channel[0]=='H':\n",
    "                    tr.stats.channel=\"B%s\" % tr.stats.channel[1:]\n",
    "            if int(tr.stats.sampling_rate)==1:\n",
    "                if tr.stats.channel[0]=='H' or tr.stats.channel[0]=='B':\n",
    "                    tr.stats.channel=\"L%s\" % tr.stats.channel[1:]\n",
    "            #print(tr)\n",
    "            st.append(tr)\n",
    "    print('Final Stream object to write')\n",
    "    print(st)\n",
    "    sdsobj.stream = st\n",
    "    successful = sdsobj.write()\n",
    "    if successful:\n",
    "        print(\"Wrote whole Stream object to SDS\")\n",
    "    else: \n",
    "        print(\"Failed to write entire Stream object:\")\n",
    "        print(df)\n",
    "    return successful\n",
    "\n",
    "\n",
    "def removed_unnamed_columns(df):\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    return df\n",
    "\n",
    "def localtime2utc(this_dt):\n",
    "    hours = 4\n",
    "    if this_dt>obspy.UTCDateTime(2022,11,6,2,0,0):\n",
    "        hours = 5\n",
    "    localTimeCorrection = 3600 * hours\n",
    "    return this_dt + localTimeCorrection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(HOME, 'Documents', 'GitHub', 'tremorExplorer', 'lib'))\n",
    "import SDS\n",
    "sdsobj = SDS.SDSobj(SDS_TOP, sds_type='D', format='MSEED')\n",
    "transducersCSVfile = os.path.join(WELLDATA_TOP, 'transducer_metadata.csv')\n",
    "\n",
    "# Parse lookuptable and convert good CSV files to SDS\n",
    "lookuptableDF = removed_unnamed_columns(pd.read_csv(lookuptable))\n",
    "lookuptableDF = lookuptableDF.sort_values(by=['starttime'])\n",
    "print(\"lookuptableDF = \\n\", lookuptableDF.columns)\n",
    "\n",
    "transducersDF = removed_unnamed_columns(pd.read_csv(transducersCSVfile))\n",
    "print(\"transducersDF = \\n\",transducersDF.columns)\n",
    "\n",
    "lookuptableDF['SDS'] = False\n",
    "\n",
    "sds_column_exists = False\n",
    "if 'SDS' in lookuptableDF.columns:\n",
    "    sds_column_exists = True\n",
    "\n",
    "for index, row in lookuptableDF.iterrows():\n",
    "    print(row)\n",
    "    row_to_sds_done = False\n",
    "    if row['passed']:\n",
    "        if sds_column_exists:\n",
    "            row_to_sds_done = row['SDS']\n",
    "        if not row_to_sds_done:\n",
    "            df2 = pd.read_csv(row['outputfile'])\n",
    "            print(f\"- writing {row['outputfile']} to SDS\")\n",
    "            print(\"row = \\n \",row)\n",
    "            #print(\"sdsobj = \\n\", sdsobj)\n",
    "            successful = convert2sds(df2, sdsobj, transducersDF)\n",
    "            lookuptableDF.at[index,'SDS'] = successful\n",
    "            if successful:\n",
    "                lookuptableDF.to_csv(lookuptable)\n",
    "del sdsobj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
