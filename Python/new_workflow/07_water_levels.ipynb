{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read YYYYMMDD.pkl files, add water level columns, and save as YYYYMMDD_final.pkl files\n",
    "\n",
    "## 1. Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import header\n",
    "paths = header.setup_environment()\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#print(paths)\n",
    "if platform.system()=='Darwin':\n",
    "    INPUTDIR = '/Users/thompsong/Dropbox/PROFESSIONAL/RESEARCH/3_Project_Documents/NASAprojects/201602_Rocket_Seismology/DATA/2022_DATA/WellData/O5_DAILY_PSI'\n",
    "else:\n",
    "    INPUTDIR = os.path.join(paths['DROPBOX_DATA_TOP'], 'WellData', '05_DAILY_PSI')\n",
    "OUTPUTDIR = INPUTDIR.replace('05_DAILY_PSI', '07_DAILY_WLM')\n",
    "if not os.path.isdir(OUTPUTDIR):\n",
    "    os.makedirs(OUTPUTDIR)\n",
    "#print(os.listdir(INPUTDIR))\n",
    "import libWellData as LLE\n",
    "transducersDF = LLE.get_transducers_dataframe(paths)\n",
    "serials = LLE.watercolumns\n",
    "sensors = {'shallow':[serials[i] for i in [0,1,4]], 'intermediate':[serials[i] for i in [2,3,5]]}\n",
    "print(sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Steve's water levels Excel data (reformatted by me), create a datetime column, and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = ['shallow', 'intermediate']\n",
    "measuredWaterLevelsDF = {}\n",
    "fh, axs = plt.subplots(1,1)\n",
    "for well in wells:\n",
    "    measuredWaterLevelsDF[well] = pd.read_excel('/home/thompsong/Dropbox/waterlevels.xlsx', sheet_name=well)\n",
    "    measuredWaterLevelsDF[well].columns = measuredWaterLevelsDF[well].columns.str.replace(' ', '')\n",
    "    #display(measuredWaterLevelsDF[well])\n",
    "    measuredWaterLevelsDF[well]['datetime']  = pd.to_datetime( measuredWaterLevelsDF[well]['Date'].astype(str)+' '+measuredWaterLevelsDF[well]['Time'].astype(str))\n",
    "    display(measuredWaterLevelsDF[well])\n",
    "    measuredWaterLevelsDF[well].rename(columns={'CorrectedElevationinFeet(NAVD)':'NAVD88_Feet'}, inplace=True)\n",
    "    measuredWaterLevelsDF[well].plot(ax=axs, x='datetime', y='NAVD88_Feet', label=well, style='o', ylabel='Water Level (NAV88D, Feet)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read YYYYMMDD.pkl for days where we have Steve's water level measurements, plot them, and compute differences\n",
    "loop over dates, read the daily pickle files YYYYMMDD.pkl which are in PSI and depth corrected - and estimate water level above NAVD88 in meters\n",
    "- despike the data for each well/sensor, \n",
    "- convert it to feet of water, \n",
    "- convert estimated water level from feet to meters\n",
    "- save the corrected data to YYYYMMDD_wlm.pkl, with new columns like serialno_wlm\n",
    "we downsample the data for plotting\n",
    "for each of Steve's water level measurements, we compare with the estimated values, and save this as a DataFrame/CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of unique dates for which Steve made measurements\n",
    "dates = measuredWaterLevelsDF['shallow']['Date'].unique()\n",
    "#print(dates)\n",
    "\n",
    "lod = []\n",
    "for d in dates:\n",
    "\n",
    "    try:\n",
    "        pklfile = os.path.join(INPUTDIR, f'{d.strftime(\"%Y%m%d\")}.pkl')\n",
    "        daydf = pd.read_pickle(pklfile)\n",
    "        \n",
    "    except:\n",
    "        print(f'Pickle file {pklfile} for {d} does not exist, trying previous day') # for 2022-12-03, and 2022-12-02 is bad\n",
    "        if d==pd.to_datetime('2022-12-03'):\n",
    "            filed = d - pd.Timedelta(hours=48)\n",
    "            pklfile = os.path.join(INPUTDIR, f'{filed.strftime(\"%Y%m%d\")}.pkl')\n",
    "            daydf = pd.read_pickle(pklfile)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # drop Temperature columns\n",
    "    #daydf.drop(columns=daydf.columns[daydf.columns.str.startswith('Therm')], inplace=True)\n",
    "    #display(daydf)\n",
    "\n",
    "    # Loop over sensors in each well. Create two new columns like 1224621_corrected, and 1226421_wl\n",
    "    for well in wells:\n",
    "        for serial in sensors[well]:\n",
    "            col = f'{serial}_corrected'\n",
    "            newcol = f'{serial}_wlm'\n",
    "            print('\\ndespiking', d, well, col)\n",
    "            wlmseries = LLE.median_despike(daydf[col], 30*100*60, threshold=1/12) # 30 minutes of data. 1 inch max departure from median in that time.\n",
    "            daydf[newcol] = LLE.psi2meters(wlmseries)\n",
    "\n",
    "    # Save the dataframe with these two new columns per sensor - not really needed, since we will loop over all dates later, not just measurement dates\n",
    "    #pkloutfile = os.path.join(INPUTDIR, f'{d.strftime(\"%Y%m%d\")}_feet.pkl')\n",
    "    #daydf.to_pickle(pkloutfile)\n",
    "    \n",
    "    # downsample to 1-minute for plotting purposes\n",
    "    daydf.set_index('datetime', inplace=True)\n",
    "    daydf = daydf.resample('1min').median()\n",
    "    daydf.reset_index(inplace=True)\n",
    "\n",
    "    # plot estimated and measured water levels & compute difference between them\n",
    "    fh, axs = plt.subplots(2,1)\n",
    "    for i, well in enumerate(wells):\n",
    "        #print('*******************')\n",
    "        #print(f'**** {well} Well ****')\n",
    "        wlm_cols = [serialno + '_wlm' for serialno in sensors[well]]\n",
    "        daydf.plot(ax=axs[i], x='datetime', y=wlm_cols) # plot estimated water levels\n",
    "\n",
    "        # filter Steve's measurements for this day, plot for each well\n",
    "        truedf = measuredWaterLevelsDF[well]\n",
    "        mindt = min( [d,daydf['datetime'].min()] )\n",
    "        trueday = truedf[(truedf['datetime']>mindt) & (truedf['datetime']<d+pd.Timedelta(hours=24))]\n",
    "        trueday['wlm'] = LLE.feet2meters(trueday['NAVD88_Feet'])\n",
    "        trueday.plot(ax=axs[i], x='datetime',y='wlm', style='o', label='measured', ylabel='Water Level (m, NAVD88)', xlim=[mindt,d+pd.Timedelta(hours=24)], title=well)\n",
    "\n",
    "        # difference between estimated and measured times \n",
    "        for j, row in trueday.iterrows():\n",
    "            #print(f'Measured {row[\"NAVD88_Feet\"]} at {row[\"datetime\"]}')\n",
    "            for serial in wlm_cols: #sensors[well]:\n",
    "                serialdf = daydf.copy().dropna(subset=[serial])\n",
    "                serialdf['timediff'] = abs(serialdf['datetime']-row['datetime'])\n",
    "                timediff = serialdf['timediff'].min()\n",
    "                idx = serialdf['timediff'].idxmin()\n",
    "                datadf = serialdf.loc[idx]\n",
    "                #print(f'- Estimated {datadf[serial]:.3f} feet at {datadf[\"datetime\"]} from sensor {serial}: time diff={timediff}')\n",
    "                \n",
    "                # here we effectively are adding a new row to the waterleveldf dataframe\n",
    "                lod.append({'well':well, 'serial':serial, 'measured_datetime':row['datetime'], 'measured_wlm':row['wlm'], \\\n",
    "                            'estimated_datetime':datadf['datetime'], 'estimated_wlm':datadf[serial], 'datetime_diff':timediff, 'wlm_diff':row['wlm']-datadf[serial]})\n",
    "\n",
    "    plt.show()\n",
    "    waterleveldf = pd.DataFrame(lod)\n",
    "    \n",
    "display(waterleveldf)\n",
    "\n",
    "# save waterlevel dataframe, which captures differences in estimated and measured water levels\n",
    "waterleveldf.to_csv(os.path.join(OUTPUTDIR, 'waterleveldf.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. estimate water level height corrections needed to best fit estimated water levels with measured levels\n",
    "* plot of water level difference between measured and estimated for each sensor. \n",
    "* create a 1-minute sampled timeseries of the difference, using linear interpolation\n",
    "* save this as a height_correction.csv file for each sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heightshiftdfs = {}\n",
    "for well in wells:\n",
    "    fig, axs = plt.subplots(len(sensors[well]),1)\n",
    "    dfwell = waterleveldf[waterleveldf['well']==well]\n",
    "    \n",
    "    for i,serial in enumerate(sensors[well]):\n",
    "        dfsensor = dfwell[dfwell['serial']==serial]\n",
    "        dfsensor.plot(ax=axs[i], x='estimated_datetime', y='wlm_diff', ylabel='meters', legend=False, title=f'Water Level Difference (M-E) for sensor {serial}', style='o-', grid=True)\n",
    "        print('interpolating water level correction for ',serial)\n",
    "\n",
    "        # resample measured data from intermittent sparse to 1-minute\n",
    "        thisdf = dfsensor[['measured_datetime', 'wlm_diff']]\n",
    "        thisdf.set_index('measured_datetime', inplace=True)\n",
    "        thisdf = thisdf.resample('1min').interpolate()\n",
    "        thisdf.reset_index(inplace=True)\n",
    "        heightshiftdfs[serial] = thisdf\n",
    "        thisdf.plot(ax=axs[i], x='measured_datetime',y='wlm_diff', label='interp')\n",
    "        hcfile = os.path.join(OUTPUTDIR, f'{serial}_height_correction_meters.csv')\n",
    "        print(f'Saving {hcfile}')\n",
    "        thisdf.to_csv(hcfile, index=False)\n",
    "\n",
    "grouped=waterleveldf.groupby(['serial'])\n",
    "for name,group in grouped:\n",
    "    print(f'Water level estimated for {name} is on average too low compared to measured value by {group[\"wlm_diff\"].mean():.3f} meters')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process all days\n",
    "* loop over all days. we will:\n",
    "* - choose an output filename YYYYMMDD_final.pkl\n",
    "* - choose an output plot YYYYMMDD_final.png\n",
    "* - load the YYYYMMDD.pkl file if neither of the above exist\n",
    "* - drop any Thermal columns\n",
    "* - loop over wells\n",
    "*   - loop over sensors\n",
    "*   - despike the data\n",
    "*   - convert water level in meters\n",
    "*   - load height correction data from last step - which corrects estimates to measured data at certain times\n",
    "*  - resample height correction data from 60-s to 100 Hz\n",
    "*   - creates a column of the height correction labelled {serial}_wlmcorr\n",
    "* - saves the data to YYYYMMDD.pkl in output directory (different from input)\n",
    "* - creates a dayplot YYYYMMDD.png\n",
    "\n",
    "Must do the height correction first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "despiking 2022-07-21 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-21 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-21 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-21 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-21 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-21 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-21 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-21 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-21 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-21 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-21 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-21 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-22 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-22 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-22 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-22 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-22 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-22 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-22 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-22 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-22 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-22 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-22 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-22 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-23 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-23 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-23 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-23 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-23 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-23 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-23 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-23 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-23 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-23 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-23 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-23 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-24 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-24 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-24 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-24 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-24 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-24 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-24 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-24 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-24 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-24 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-24 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-24 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-25 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-25 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-25 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-25 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-25 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-25 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-25 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-25 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-25 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-25 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-25 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-25 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-26 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-26 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-26 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-26 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-26 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-26 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-26 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-26 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-26 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-26 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-26 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-26 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-27 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-27 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-27 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-27 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-27 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-27 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-27 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-27 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-27 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-27 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-27 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-27 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-28 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-28 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-28 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-28 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-28 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-28 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-28 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-28 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-28 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-28 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-28 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-28 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-29 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-29 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-29 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-29 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-29 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-29 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-29 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-29 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-29 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-29 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-29 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-29 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-30 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-30 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-30 00:00:00 shallow 1226421\n",
      "\n",
      "correcting 2022-07-30 00:00:00 shallow 1226421\n",
      "\n",
      "despiking 2022-07-30 00:00:00 shallow 1226423\n",
      "\n",
      "correcting 2022-07-30 00:00:00 shallow 1226423\n",
      "\n",
      "despiking 2022-07-30 00:00:00 intermediate 2151691\n",
      "\n",
      "correcting 2022-07-30 00:00:00 intermediate 2151691\n",
      "\n",
      "despiking 2022-07-30 00:00:00 intermediate 2149882\n",
      "\n",
      "correcting 2022-07-30 00:00:00 intermediate 2149882\n",
      "\n",
      "despiking 2022-07-30 00:00:00 intermediate 2151692\n",
      "\n",
      "correcting 2022-07-30 00:00:00 intermediate 2151692\n",
      "*******************\n",
      "**** shallow Well ****\n",
      "*******************\n",
      "**** intermediate Well ****\n",
      "\n",
      "despiking 2022-07-31 00:00:00 shallow 1226419\n",
      "\n",
      "correcting 2022-07-31 00:00:00 shallow 1226419\n",
      "\n",
      "despiking 2022-07-31 00:00:00 shallow 1226421\n"
     ]
    }
   ],
   "source": [
    "# loop over each pklfile\n",
    "startdate = pd.to_datetime('2022-07-21')\n",
    "enddate = pd.to_datetime('2022-12-02')\n",
    "d = startdate\n",
    "while d < enddate:\n",
    "    pkloutfile = os.path.join(OUTPUTDIR, f'{d.strftime(\"%Y%m%d\")}.pkl')\n",
    "\n",
    "    # check if this day already processed\n",
    "    if os.path.isfile(pkloutfile.replace('.pkl', '.png')):\n",
    "        d = d + pd.Timedelta(hours=24)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        pklfile = os.path.join(INPUTDIR, f'{d.strftime(\"%Y%m%d\")}.pkl')\n",
    "        daydf = pd.read_pickle(pklfile)\n",
    "    except:\n",
    "        print(f'Pickle file {pklfile} for {d} does not exist')\n",
    "        d = d + pd.Timedelta(hours=24)\n",
    "        continue\n",
    "    else:\n",
    "        daydf.drop(columns=daydf.columns[daydf.columns.str.startswith('Therm')], inplace=True)\n",
    "        for well in wells:\n",
    "            for serial in sensors[well]:\n",
    "                corrcol = f'{serial}_corrected'\n",
    "                wlmcol = f'{serial}_wlm'\n",
    "                hccol = f'{wlmcol}_hc'\n",
    "                \n",
    "                if not corrcol in daydf.columns:\n",
    "                    continue\n",
    "\n",
    "                this_transducer = LLE.get_transducer_metadata(serial, transducersDF)          \n",
    "                wlmseries = LLE.psi2meters(daydf[corrcol])\n",
    "                print('\\ndespiking', d, well, serial)\n",
    "                daydf[wlmcol] = LLE.median_despike(wlmseries, 30*100*60, threshold=1/12) # 30 minutes of data. 1 inch max departure from median in that time. # MOVEDS THIS FROM 4 LINES UP\n",
    "        \n",
    "                # load height correction data, which is every minute, and interpolate to 10 ms, then merge into daydf\n",
    "                # save new columns serial_wldiff and serial_wlm_corrected\n",
    "                print('\\ncorrecting', d, well, serial)\n",
    "                csvfile = os.path.join(OUTPUTDIR, f'{serial}_height_correction_feet.csv')\n",
    "                if os.path.isfile(csvfile):\n",
    "                    hcdf = pd.read_csv(csvfile, index_col=None)\n",
    "                    hcdf['measured_datetime'] = pd.to_datetime(hcdf['measured_datetime'])\n",
    "                    hcdf.set_index('measured_datetime', inplace=True)\n",
    "                    hcdf = hcdf.loc[daydf['datetime'].min():daydf['datetime'].max()] \n",
    "                    hcdf = hcdf.resample('10ms').interpolate()\n",
    "                    hcdf.reset_index(inplace=True)\n",
    "                    newcol = f'{serial}_wlmdiff'\n",
    "                    hcdf.rename(columns={'wlm_diff':newcol}, inplace=True)\n",
    "\n",
    "                    # join\n",
    "                    daydf = daydf.merge(hcdf, left_on='datetime', right_on='measured_datetime', how='inner')\n",
    "                    daydf.drop(columns='measured_datetime', inplace=True)\n",
    "                    daydf[hccol] = daydf[wlmcol] + daydf[newcol] \n",
    "        \n",
    "        daydf.to_pickle(pkloutfile)\n",
    "\n",
    "        # downsample for plotting\n",
    "        daydf.set_index('datetime', inplace=True)\n",
    "        daydf = daydf.resample('1min').median()\n",
    "        daydf.reset_index(inplace=True)\n",
    "\n",
    "        fh, axs = plt.subplots(2,1)\n",
    "        for i, well in enumerate(wells):\n",
    "            print('*******************')\n",
    "            print(f'**** {well} Well ****')\n",
    "            available_sensors = list(set(daydf.columns) & set(sensors[well])) \n",
    "            wlm_channels = [f'{chan}_wlm' for chan in available_sensors]\n",
    "            if len(wlm_channels)>0:\n",
    "                daydf.plot(ax=axs[i], x='datetime', y=wlm_channels, ylabel='Water Level (m, NAVD88)', xlim=[d,d+pd.Timedelta(hours=24)], title=well)\n",
    "        plt.savefig(pkloutfile.replace('.pkl', '.png'))\n",
    "\n",
    "    \n",
    "    d = d + pd.Timedelta(hours=24)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "passoft3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
